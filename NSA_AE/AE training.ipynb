{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "b3190377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "bb96f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.autoencoder import AutoEncoder, NSAAutoEncoder\n",
    "from src.utils import *\n",
    "from src.loss import RTDLoss, NSALoss, LID_NSALoss\n",
    "from src.top_ae import TopologicallyRegularizedAutoencoder\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "63bb080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_name\":\"F-MNIST\",\n",
    "    \"version\":\"k_L256_N256\",\n",
    "    \"model_name\":\"default\",\n",
    "    \"max_epochs\":250,\n",
    "    \"gpus\":[0],\n",
    "    \"rtd_every_n_batches\":1,\n",
    "    \"rtd_start_epoch\":60,\n",
    "    \"rtd_l\":1.0, # rtd loss\n",
    "    \"nsa_every_n_batches\":1,\n",
    "    \"nsa_start_epoch\":0,\n",
    "    \"nsa_l\":1.0, # rtd loss\n",
    "    \"n_runs\":1, # number of runs for each model\n",
    "    \"card\":50, # number of points on the persistence diagram\n",
    "    \"n_threads\":1, # number of threads for parallel ripser computation of pers homology\n",
    "    \"latent_dim\":16, # latent dimension (2 or 3 for vizualization purposes)\n",
    "    \"input_dim\":28*28,\n",
    "    \"n_hidden_layers\":3,\n",
    "    \"hidden_dim\":512,\n",
    "    \"batch_size\":256,\n",
    "    \"engine\":\"ripser\",\n",
    "    \"is_sym\":True,\n",
    "    \"lr\":1e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "90495af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim, latent_dim=2, n_hidden_layers=2, m_type='encoder', **kwargs):\n",
    "    n = int(np.log2(input_dim))-1\n",
    "    layers = []\n",
    "    if m_type == 'encoder':\n",
    "        in_dim = input_dim\n",
    "        if input_dim  // 2 >= latent_dim:\n",
    "            out_dim = input_dim // 2\n",
    "        else:\n",
    "            out_dim = input_dim\n",
    "        for i in range(min(n, n_hidden_layers)):\n",
    "            layers.extend([nn.Linear(in_dim, out_dim), nn.ReLU()])\n",
    "            in_dim = out_dim\n",
    "            if in_dim  // 2 >= latent_dim:\n",
    "                out_dim = in_dim // 2\n",
    "            else:\n",
    "                out_dim = in_dim\n",
    "        layers.extend([nn.Linear(in_dim, latent_dim)])\n",
    "    elif m_type == 'decoder':\n",
    "        in_dim = latent_dim\n",
    "        out_dim = latent_dim * 2\n",
    "        for i in range(min(n, n_hidden_layers)):\n",
    "            layers.extend([nn.Linear(in_dim, out_dim), nn.ReLU()])\n",
    "            in_dim = out_dim\n",
    "            out_dim *= 2\n",
    "        layers.extend([nn.Linear(in_dim, input_dim)])\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def get_list_of_models(**config):\n",
    "    # define a list of models\n",
    "    encoder = get_linear_model(\n",
    "        m_type='encoder',\n",
    "        **config\n",
    "    )\n",
    "    decoder = get_linear_model(\n",
    "        m_type='decoder',\n",
    "        **config\n",
    "    )\n",
    "    models = {\n",
    "        # 'Basic AutoEncoder':AutoEncoder(\n",
    "        #    encoder = encoder,\n",
    "        #     decoder = decoder,\n",
    "        #     MSELoss = nn.MSELoss(),\n",
    "        #     **config\n",
    "        # ),\n",
    "        # 'Topological AutoEncoder':TopologicallyRegularizedAutoencoder(\n",
    "        #     encoder = encoder,\n",
    "        #     decoder = decoder,\n",
    "        #     MSELoss = nn.MSELoss(),\n",
    "        #     **config\n",
    "        # ),\n",
    "        # 'RTD AutoEncoder H1':AutoEncoder(\n",
    "        #     encoder = encoder,\n",
    "        #     decoder = decoder,\n",
    "        #     RTDLoss = RTDLoss(dim=1, lp=1.0,  **config), # only H1\n",
    "        #     MSELoss = nn.MSELoss(),\n",
    "        #     **config\n",
    "        # ),\n",
    "        'LID_NSA AutoEncoder':NSAAutoEncoder(\n",
    "            encoder = encoder,\n",
    "            decoder = decoder,\n",
    "            NSALoss = LID_NSALoss(k=config['batch_size']-1), # only H1\n",
    "            MSELoss = None,\n",
    "            **config\n",
    "        ),\n",
    "    }\n",
    "    return models, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "81219803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_with_matrix(samples):\n",
    "    indicies, data, labels = zip(*samples)\n",
    "    data, labels = torch.tensor(np.asarray(data)), torch.tensor(np.asarray(labels))\n",
    "    if len(data.shape) > 2:\n",
    "        dist_data = torch.flatten(data, start_dim=1)\n",
    "    else:\n",
    "        dist_data = data\n",
    "    x_dist = torch.cdist(dist_data, dist_data, p=2) / np.sqrt(dist_data.shape[1])\n",
    "#     x_dist = (x_dist + x_dist.T) / 2.0 # make symmetrical (cdist is prone to computational errors)\n",
    "    return data, x_dist, labels\n",
    "\n",
    "def collate_with_matrix_geodesic(samples):\n",
    "    indicies, data, labels, dist_data = zip(*samples)\n",
    "    data, labels = torch.tensor(np.asarray(data)), torch.tensor(np.asarray(labels))\n",
    "    x_dist = torch.tensor(np.asarray(dist_data)[:, indicies])\n",
    "    return data, x_dist, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "c0fb1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = config['dataset_name']\n",
    "if dataset_name in ['COIL-20','COIL-100']:\n",
    "    train_data = np.load(f'data/{dataset_name}/prepared/data.npy').astype(np.float32)\n",
    "elif dataset_name.startswith('LinkPrediction'):\n",
    "    train_data = np.load(f'data/{dataset_name}/LP_3_200.npz')\n",
    "    train_data = dict(train_data)\n",
    "    print(train_data.keys())\n",
    "    key = list(train_data.keys())[-1]\n",
    "    print(key)\n",
    "    train_data = train_data[key]\n",
    "else:\n",
    "    train_data = np.load(f'data/{dataset_name}/prepared/train_data.npy').astype(np.float32)\n",
    "\n",
    "\n",
    "try:        \n",
    "    test_data = np.load(f'data/{dataset_name}/prepared/test_data.npy').astype(np.float32)\n",
    "except FileNotFoundError:\n",
    "    ids = np.random.choice(np.arange(len(train_data)), size=int(0.2*len(train_data)), replace=False)\n",
    "    test_data = train_data[ids]\n",
    "\n",
    "try:\n",
    "    if dataset_name in ['COIL-20','COIL-100']:\n",
    "        print(\"Inside here\")\n",
    "        train_labels = np.load(f'data/{dataset_name}/prepared/labels.npy')\n",
    "    elif dataset_name.startswith('LinkPrediction'):\n",
    "        train_labels = np.arange(1,len(train_data)+1)\n",
    "    else:\n",
    "        train_labels = np.load(f'data/{dataset_name}/prepared/train_labels.npy')\n",
    "except FileNotFoundError:\n",
    "    train_labels = None\n",
    "\n",
    "try:\n",
    "    test_labels = np.load(f'data/{dataset_name}/prepared/test_labels.npy')\n",
    "except FileNotFoundError:\n",
    "    if train_labels is None:\n",
    "        test_labels = None\n",
    "    else:\n",
    "        test_labels = train_labels[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "3360bd60-ef8f-49b2-9343-440937ada962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[9 0 0 3 0 2 7 2 5 5]\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "[9 2 1 1 6 1 4 6 5 7]\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels[:10])\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels[:10])\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "c5d89152-699b-4cf3-b04f-9a32e78702a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "3ea3ca33-162b-4a76-acf4-9a5976f22a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workflow\n",
    "\n",
    "#Now pick a random index and add that index to the queue\n",
    "#for each element in the queue, as you pop it\n",
    "#1 add all the neighbors in the neighbors to the queue, either k or k+ connections necessary to form a single connected component\n",
    "#Remove the node along with all its connections (edges) from the nearest neighbors graph and from potential indices that I can initially pick from\n",
    "#Repeat until I pop batch_size elements.\n",
    "#After one batch is ready, check for 1 cc and fix cc\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.sparse.csgraph import connected_components, shortest_path\n",
    "from src.utils import _fix_connected_components\n",
    "import copy\n",
    "\n",
    "\n",
    "class NearestNeighborBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, num_neighbors):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_neighbors = num_neighbors\n",
    "        #Given input data X, compute k nearest neighbors for each point\n",
    "        self.kng = kneighbors_graph(self.dataset.data, n_neighbors=self.num_neighbors, mode='connectivity')\n",
    "        self.kng_dict_front = self.create_kng_dict_front()\n",
    "        self.kng_dict_back = self.create_kng_dict_back()\n",
    "        #Use fix connected components to generate one connected component\n",
    "        num_ccs, component_labels = connected_components(self.kng)\n",
    "        if num_ccs > 1:\n",
    "            self.kng = _fix_connected_components(self.dataset.data, self.kng, num_ccs, component_labels, mode='connectivity', metric='euclidean')\n",
    "            #Check again to confirm if it worked\n",
    "            num_ccs, component_labels = connected_components(self.kng)\n",
    "            if num_ccs >1:\n",
    "                raise ValueError(\"Increase nearest neighbor size; cannot generate a single connected component with the given knn size.\")\n",
    "\n",
    "    def create_kng_dict_front(self):\n",
    "        dict = [list(self.nearest_neighbors(i)) for i in range(len(self.dataset))]\n",
    "        return dict\n",
    "        \n",
    "    def create_kng_dict_back(self):\n",
    "        dict = [list(self.nearest_neighbors_of(i)) for i in range(len(self.dataset))]\n",
    "        return dict\n",
    "\n",
    "    def nearest_neighbors(self, index, kng=None):\n",
    "        if kng is None:\n",
    "            kng = self.kng\n",
    "        return kng.getrow(index).nonzero()[1]\n",
    "\n",
    "    def nearest_neighbors_of(self, index, kng=None):\n",
    "        if kng is None:\n",
    "            kng = self.kng\n",
    "        return kng.getcol(index).nonzero()[0]\n",
    "        \n",
    "    # def remove_point_existence(self, index):\n",
    "    #     for i in self.kng_dict_back[index]:\n",
    "    #         self.kng_dict_front[i].remove(index)\n",
    "    #     for i in self.kng_dict_front[index]:\n",
    "    #         self.kng_dict_back[i].remove(index)\n",
    "    #     self.kng_dict_front[index] = []\n",
    "    #     self.kng_dict_back[index] = []\n",
    "    \n",
    "    def __iter__(self):\n",
    "        print(\"Running iter\")\n",
    "        # iter_kng = self.kng.copy()\n",
    "        numbatches = len(self.dataset) // self.batch_size\n",
    "        indices = list(range(len(self.dataset)))\n",
    "        random.shuffle(indices)\n",
    "        indices = indices[:numbatches]\n",
    "        # self.kng_dict_front = self.create_kng_dict_front()\n",
    "        # self.kng_dict_back = self.create_kng_dict_back()\n",
    "        # indices = set(indices)\n",
    "        batches = []\n",
    "        while indices:\n",
    "            kng_front = copy.deepcopy(self.kng_dict_front)\n",
    "            kng_back = copy.deepcopy(self.kng_dict_back)\n",
    "            # if len(indices) < self.batch_size:\n",
    "            #     #Add functionality to sort the data in case you want to retain ordering\n",
    "            #     batches.append(indices)\n",
    "            #     break\n",
    "            # print(indices[:10])\n",
    "            batch = set()\n",
    "            queue = []\n",
    "            queue_set = set()\n",
    "            next_point = indices.pop()\n",
    "            # print(\"Current index:\",next_point)\n",
    "            # print(\"Remaining indices:\",len(indices))\n",
    "            # print(\"Number of batches:\", len(batches))\n",
    "            batch.add(next_point)\n",
    "            queue.extend(self.kng_dict_front[next_point])\n",
    "            queue_set.update(self.kng_dict_front[next_point])\n",
    "            for i in kng_back[next_point]:\n",
    "                kng_front[i].remove(next_point)\n",
    "            for i in kng_front[next_point]:\n",
    "                kng_back[i].remove(next_point)\n",
    "            kng_front[next_point] = []\n",
    "            kng_back[next_point] = []\n",
    "            # self.remove_point_existence(next_point)\n",
    "            while len(batch) + len(queue) < self.batch_size:\n",
    "                # print(\"Queue Length:\",len(queue))\n",
    "                if queue:\n",
    "                    next_point = queue.pop(0)\n",
    "                    if next_point not in batch:\n",
    "                        batch.add(next_point)\n",
    "                        # indices.remove(next_point)\n",
    "                        for new_point in self.kng_dict_front[next_point]:\n",
    "                            if new_point not in queue_set:\n",
    "                                queue.append(new_point)\n",
    "                                queue_set.add(new_point)\n",
    "                        for i in kng_back[next_point]:\n",
    "                            kng_front[i].remove(next_point)\n",
    "                        for i in kng_front[next_point]:\n",
    "                            kng_back[i].remove(next_point)\n",
    "                        kng_front[next_point] = []\n",
    "                        kng_back[next_point] = []\n",
    "                        # queue.extend(self.kng_dict_front[next_point])\n",
    "                        # self.remove_point_existence(next_point)\n",
    "                else:\n",
    "                #     # print(\"Queue is empty but batch requirements are not met starting from point:\",next_point)\n",
    "                    if indices:\n",
    "                        next_point = indices.pop()\n",
    "                        batch.add(next_point)\n",
    "                        queue.extend(self.kng_dict_front[next_point])\n",
    "                        queue_set.update(self.kng_dict_front[next_point])\n",
    "                        for i in kng_back[next_point]:\n",
    "                            kng_front[i].remove(next_point)\n",
    "                        for i in kng_front[next_point]:\n",
    "                            kng_back[i].remove(next_point)\n",
    "                        kng_front[next_point] = []\n",
    "                        kng_back[next_point] = []\n",
    "                        # queue.extend(self.kng_dict_front[next_point])\n",
    "                        # self.remove_point_existence(next_point)\n",
    "                # Remove duplicates in queue\n",
    "                #queue = list(dict.fromkeys(queue))\n",
    "            batch.update(queue)\n",
    "            # print(\"Created a batch of size:\",len(batch))\n",
    "        \n",
    "            batches.append(list(batch))\n",
    "            # print(\"Previous batch size:\", len(batches[-1]))\n",
    "            #This might not be necessary\n",
    "            # num_ccs, component_labels = connected_components(iter_kng)\n",
    "            # if num_ccs > 1:\n",
    "            #     print(\"Connected component check failed during batching\")\n",
    "            #     # iter_kng = _fix_connected_components(self.dataset.data, iter_kng, num_ccs, component_labels, mode='connectivity', metric='euclidean')\n",
    "            #     # #Check to see if it was fixed\n",
    "            #     # num_ccs, component_labels = connected_components(iter_kng)\n",
    "            #     # if n_ccs >1:\n",
    "            #     #     raise ValueError(\"Connected component check failed during batching; increase nearest neighbor size.\")\n",
    "        \n",
    "        return iter(batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "fd6b346e-8495-43ea-afb5-fd2807af91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workflow\n",
    "\n",
    "#Now pick a random index and add that index to the queue\n",
    "#for each element in the queue, as you pop it\n",
    "#1 add all the neighbors in the neighbors to the queue, either k or k+ connections necessary to form a single connected component\n",
    "#Remove the node along with all its connections (edges) from the nearest neighbors graph and from potential indices that I can initially pick from\n",
    "#Repeat until I pop batch_size elements.\n",
    "#After one batch is ready, check for 1 cc and fix cc\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.sparse.csgraph import connected_components, shortest_path\n",
    "from src.utils import _fix_connected_components\n",
    "import copy\n",
    "import threading, queue\n",
    "\n",
    "\n",
    "class NearestNeighborBatchSamplerMulti(Sampler):\n",
    "    def __init__(self, dataset, batch_size, num_neighbors, num_threads=24):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_neighbors = num_neighbors\n",
    "        #Given input data X, compute k nearest neighbors for each point\n",
    "        self.kng = kneighbors_graph(self.dataset.data, n_neighbors=self.num_neighbors, mode='connectivity')\n",
    "        self.kng_dict_front = self.create_kng_dict_front()\n",
    "        #Use fix connected components to generate one connected component\n",
    "        num_ccs, component_labels = connected_components(self.kng)\n",
    "        if num_ccs > 1:\n",
    "            self.kng = _fix_connected_components(self.dataset.data, self.kng, num_ccs, component_labels, mode='connectivity', metric='euclidean')\n",
    "            #Check again to confirm if it worked\n",
    "            num_ccs, component_labels = connected_components(self.kng)\n",
    "            if num_ccs >1:\n",
    "                raise ValueError(\"Increase nearest neighbor size; cannot generate a single connected component with the given knn size.\")\n",
    "        self.results_queue = queue.Queue()\n",
    "        self.num_threads = num_threads\n",
    "        self.indices = []\n",
    "\n",
    "    def create_kng_dict_front(self):\n",
    "        dict = [list(self.nearest_neighbors(i)) for i in range(len(self.dataset))]\n",
    "        return dict\n",
    "        \n",
    "    def create_kng_dict_back(self):\n",
    "        dict = [list(self.nearest_neighbors_of(i)) for i in range(len(self.dataset))]\n",
    "        return dict\n",
    "\n",
    "    def nearest_neighbors(self, index, kng=None):\n",
    "        if kng is None:\n",
    "            kng = self.kng\n",
    "        return kng.getrow(index).nonzero()[1]\n",
    "\n",
    "    def nearest_neighbors_of(self, index, kng=None):\n",
    "        if kng is None:\n",
    "            kng = self.kng\n",
    "        return kng.getcol(index).nonzero()[0]\n",
    "\n",
    "    def one_minibatch(self, point):\n",
    "        batch = set()\n",
    "        point_queue = []\n",
    "        queue_set = set()\n",
    "        batch.add(point)\n",
    "        point_queue.extend(self.kng_dict_front[point])\n",
    "        queue_set.update(self.kng_dict_front[point])\n",
    "        while len(batch) + len(point_queue) < self.batch_size:\n",
    "            if point_queue:\n",
    "                next_point = point_queue.pop(0)\n",
    "                if next_point not in batch:\n",
    "                    batch.add(next_point)\n",
    "                    for new_point in self.kng_dict_front[next_point]:\n",
    "                        if new_point not in queue_set:\n",
    "                            point_queue.append(new_point)\n",
    "                            queue_set.add(new_point)\n",
    "            else:\n",
    "                if self.indices:\n",
    "                    next_point = self.indices.pop()\n",
    "                    batch.add(next_point)\n",
    "                    point_queue.extend(self.kng_dict_front[next_point])\n",
    "                    queue_set.update(self.kng_dict_front[next_point])\n",
    "        batch.update(point_queue)\n",
    "        return batch\n",
    "        \n",
    "    def thread_minibatch(self):\n",
    "        while True:\n",
    "            try:\n",
    "                point = self.indices.pop()  # Get a value to process\n",
    "            except IndexError:\n",
    "                break\n",
    "            batch = self.one_minibatch(point)\n",
    "            self.results_queue.put(batch)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        #print(\"Running iter\")\n",
    "        numbatches = len(self.dataset) // self.batch_size\n",
    "        self.indices = list(range(len(self.dataset)))\n",
    "        random.shuffle(self.indices)\n",
    "        self.indices = self.indices[:numbatches]\n",
    "        batches = []\n",
    "        threads = []\n",
    "        for _ in range(self.num_threads):\n",
    "            thread = threading.Thread(target=self.thread_minibatch)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        while not self.results_queue.empty():\n",
    "            result = self.results_queue.get()\n",
    "            batches.append(list(result))\n",
    "        return iter(batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "da2dba75-dde6-4e70-9613-18131f7e6c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[9 0 0 3 0 2 7 2 5 5]\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "[9 2 1 1 6 1 4 6 5 7]\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels[:10])\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels[:10])\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "c76d71a2-2fab-436c-9047-a9722771b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomMinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.min_vals = train_data.min()\n",
    "        self.max_vals = train_data.max()\n",
    "        self.is_fitted = True\n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.min_vals = np.min(data, axis=0)\n",
    "        self.max_vals = np.max(data, axis=0)\n",
    "        self.is_fitted = True\n",
    "        \n",
    "    def transform(self, data):\n",
    "        if not self.is_fitted:\n",
    "            raise NotFittedError\n",
    "        scaled_data = (data - self.min_vals) / (self.max_vals - self.min_vals)\n",
    "        return scaled_data\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "20d60562-287e-4175-9f25-7f77264b8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "1a8a8e29-8571-4f29-b88e-2ba639946695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, k, **kwargs):\n",
    "        super().__init__(dataset, **kwargs)\n",
    "        self.k = k\n",
    "        self.epoch = 0\n",
    "    def __iter__(self):\n",
    "        if self.epoch % self.k == 0:\n",
    "            self._iterator = self._get_iterator()\n",
    "            self.epoch = 0  # Reset the epoch counter\n",
    "        self.epoch += 1\n",
    "        return self._iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "28cc76f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train done\n"
     ]
    }
   ],
   "source": [
    "scaler = CustomMinMaxScaler()\n",
    "#scaler = None\n",
    "flatten = True\n",
    "geodesic = False\n",
    "\n",
    "train = FromNumpyDataset(\n",
    "    train_data, \n",
    "    train_labels, \n",
    "    geodesic=geodesic, \n",
    "    scaler=scaler, \n",
    "    flatten=flatten, \n",
    "    n_neighbors=2\n",
    ")\n",
    "print(\"Train done\")\n",
    "test = FromNumpyDataset(\n",
    "    test_data, \n",
    "    test_labels, \n",
    "    geodesic=geodesic, \n",
    "    scaler = train.scaler,    \n",
    "    flatten=flatten, \n",
    "    n_neighbors=2\n",
    ")\n",
    "train_sampler = NearestNeighborBatchSamplerMulti(train, config['batch_size'], num_neighbors=config['batch_size']-1, num_threads=24)\n",
    "#val_sampler = NearestNeighborBatchSampler(test, config['batch_size'], num_neighbors=5)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train, \n",
    "    batch_sampler=train_sampler, \n",
    "    num_workers=24, \n",
    "    collate_fn=collate_with_matrix_geodesic if geodesic else collate_with_matrix, \n",
    ")\n",
    "\n",
    "# train_loader = CustomDataLoader(\n",
    "#     train,\n",
    "#     batch_sampler=train_sampler,\n",
    "#     num_workers=0,\n",
    "#     k=10,\n",
    "#     collate_fn=collate_with_matrix_geodesic if geodesic else collate_with_matrix,\n",
    "# )\n",
    "\n",
    "# val_loader = DataLoader(\n",
    "#     test,\n",
    "#     batch_sampler=val_sampler,\n",
    "#     num_workers=2,\n",
    "#     collate_fn=collate_with_matrix_geodesic if geodesic else collate_with_matrix,\n",
    "# )\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     train, \n",
    "#     batch_size=config[\"batch_size\"], \n",
    "#     num_workers=24, \n",
    "#     collate_fn=collate_with_matrix_geodesic if geodesic else collate_with_matrix, \n",
    "#     shuffle=True,\n",
    "#     drop_last=True\n",
    "# )\n",
    "\n",
    "# val_loader = DataLoader(\n",
    "#     test,\n",
    "#     batch_size=config[\"batch_size\"],\n",
    "#     num_workers=24,\n",
    "#     collate_fn=collate_with_matrix_geodesic if geodesic else collate_with_matrix,\n",
    "#     shuffle=False,\n",
    "#     drop_last=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12f432-1c1c-485b-9b64-600bd47519f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "4398e80f-2e1a-43f8-a2a5-1a7b68e15187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "46a7a0ef-dab7-4985-8b10-12f616204adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0+cu117'"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "6f1cdafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, train_loader, val_loader=None, model_name='default', \n",
    "                      dataset_name='F-MNIST', gpus=[0], max_epochs=100, run=0, version=\"d1\"):\n",
    "    version = f\"{dataset_name}_{model_name}_{version}_{run}\"\n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=os.getcwd(), name='lightning_logs', version=version)\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger, \n",
    "        gpus=gpus, \n",
    "        max_epochs=max_epochs, \n",
    "        log_every_n_steps=1, \n",
    "        num_sanity_val_steps=0\n",
    "    )\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    return model\n",
    "\n",
    "def dump_figures(figures, dataset_name, version):\n",
    "    for model_name in figures:\n",
    "        figures[model_name].savefig(f'results/{dataset_name}/{model_name}_{version}.png')\n",
    "\n",
    "def train_models(train_loader, val_loader, dataset_name=\"\", max_epochs=1, gpus=[], n_neighbors=[1], n_runs=1, version='', **kwargs):\n",
    "    models, encoder, decoder = get_list_of_models(**kwargs)\n",
    "    \n",
    "    for model_name in tqdm(models, desc=f\"Training models\"):\n",
    "        if 'AutoEncoder' in model_name: # train an autoencoder\n",
    "            models[model_name] = train_autoencoder(\n",
    "                models[model_name], \n",
    "                train_loader, \n",
    "                val_loader, \n",
    "                model_name, \n",
    "                dataset_name,\n",
    "                gpus,\n",
    "                max_epochs,\n",
    "                0,\n",
    "                version\n",
    "            )\n",
    "        else: # umap / pca / t-sne (sklearn interface)\n",
    "            train_latent = models[model_name].fit_transform(train_loader.dataset.data)\n",
    "        # measure training time\n",
    "    return encoder, decoder, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "b98c06e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007964611053466797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training models",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190d04299ef04fc5bb8c50fd4a4616bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name    | Type        | Params\n",
      "----------------------------------------\n",
      "0 | encoder | Sequential  | 1.2 M \n",
      "1 | decoder | Sequential  | 1.2 M \n",
      "2 | NSALoss | LID_NSALoss | 0     \n",
      "----------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.588     Total estimated model params size (MB)\n",
      "/home/danish/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /home/danish/NSA/NSA_AE/lightning_logs/F-MNIST_LID_NSA AutoEncoder_k_L256_N256_0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/home/danish/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00626826286315918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b89090b055f45af91b7fbc2e9225af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005670785903930664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006496906280517578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0069293975830078125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([260, 260])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00638127326965332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006643533706665039,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00542902946472168,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005377054214477539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([260, 260])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005906105041503906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0060672760009765625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df24a58ac5b46219687d8a4df2d05f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter\n",
      "Running iter\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([260, 260])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([259, 259])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([256, 256])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([258, 258])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([257, 257])\n",
      "255 torch.Size([255, 255])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[503], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder, decoder, trained_models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[502], line 24\u001b[0m, in \u001b[0;36mtrain_models\u001b[0;34m(train_loader, val_loader, dataset_name, max_epochs, gpus, n_neighbors, n_runs, version, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m tqdm(models, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining models\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoEncoder\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name: \u001b[38;5;66;03m# train an autoencoder\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m         models[model_name] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mversion\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# umap / pca / t-sne (sklearn interface)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         train_latent \u001b[38;5;241m=\u001b[39m models[model_name]\u001b[38;5;241m.\u001b[39mfit_transform(train_loader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdata)\n",
      "Cell \u001b[0;32mIn[502], line 12\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, train_loader, val_loader, model_name, dataset_name, gpus, max_epochs, run, version)\u001b[0m\n\u001b[1;32m      4\u001b[0m logger \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mloggers\u001b[38;5;241m.\u001b[39mTensorBoardLogger(save_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetcwd(), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightning_logs\u001b[39m\u001b[38;5;124m'\u001b[39m, version\u001b[38;5;241m=\u001b[39mversion)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      6\u001b[0m     logger\u001b[38;5;241m=\u001b[39mlogger, \n\u001b[1;32m      7\u001b[0m     gpus\u001b[38;5;241m=\u001b[39mgpus, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     num_sanity_val_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:735\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    730\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    731\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m     )\n\u001b[1;32m    734\u001b[0m     train_dataloaders \u001b[38;5;241m=\u001b[39m train_dataloader\n\u001b[0;32m--> 735\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:682\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;124;03mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;66;03m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[1;32m    769\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1193\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;66;03m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[0;32m-> 1193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_dispatch()\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1272\u001b[0m, in \u001b[0;36mTrainer._dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_type_plugin\u001b[38;5;241m.\u001b[39mstart_predicting(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1272\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:202\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# double dispatch to initiate the training loop\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1282\u001b[0m, in \u001b[0;36mTrainer.run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1312\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1312\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:234\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m data_fetcher \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mget_profiled_dataloader(dataloader)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# as they expect that the same step is used when logging epoch end metrics even when the batch loop has\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# finished. this means the attribute does not exactly track the number of optimizer steps applied.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# TODO(@carmocca): deprecate and rename so users don't get confused\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:146\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:246\u001b[0m, in \u001b[0;36mTrainingEpochLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_check_val:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# SAVE LOGGERS (ie: Tensorboard, etc...)\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:341\u001b[0m, in \u001b[0;36mTrainingEpochLoop._run_validation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loop\u001b[38;5;241m.\u001b[39m_reload_evaluation_dataloaders()\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:109\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_fetcher \u001b[38;5;241m=\u001b[39m dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mget_profiled_dataloader(\n\u001b[1;32m    105\u001b[0m     dataloader, dataloader_idx\u001b[38;5;241m=\u001b[39mdataloader_idx\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    107\u001b[0m dl_max_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_batches[dataloader_idx]\n\u001b[0;32m--> 109\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_dataloaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:123\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_step_and_end\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 123\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:215\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 215\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py:236\u001b[0m, in \u001b[0;36mAccelerator.validation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:219\u001b[0m, in \u001b[0;36mTrainingTypePlugin.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NSA/NSA_AE/src/autoencoder.py:142\u001b[0m, in \u001b[0;36mNSAAutoEncoder.validation_step\u001b[0;34m(self, val_batch, batch_idx)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/mse_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNSALoss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsa_start_epoch \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# z_dist = self.z_dist(z)\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# z_dist = self.z_dist(z)\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     loss_nsa \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNSALoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsa_l\u001b[38;5;241m*\u001b[39mloss_nsa\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n",
      "File \u001b[0;32m~/anaconda3/envs/NSA_v1/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/NSA/NSA_AE/src/loss.py:189\u001b[0m, in \u001b[0;36mLID_NSALoss.forward\u001b[0;34m(self, X, Z)\u001b[0m\n\u001b[1;32m    187\u001b[0m normA1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantile(torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39msum(X\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)),\u001b[38;5;241m0.98\u001b[39m)\n\u001b[1;32m    188\u001b[0m normA2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantile(torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39msum(Z\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)),\u001b[38;5;241m0.98\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m nn_mask, lid_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_neighbor_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormA1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m z_dist \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcdist(Z,Z)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps\n\u001b[1;32m    191\u001b[0m z_dist \u001b[38;5;241m=\u001b[39m z_dist\u001b[38;5;241m/\u001b[39mnormA2\n",
      "File \u001b[0;32m~/NSA/NSA_AE/src/loss.py:180\u001b[0m, in \u001b[0;36mLID_NSALoss.compute_neighbor_mask\u001b[0;34m(self, X, normA1)\u001b[0m\n\u001b[1;32m    178\u001b[0m     values, indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(x_dist, x_dist\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], largest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     values, indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlargest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m values, indices \u001b[38;5;241m=\u001b[39m values[:,\u001b[38;5;241m1\u001b[39m:], indices[:,\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    182\u001b[0m norm_values\u001b[38;5;241m=\u001b[39mvalues[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mview(values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "encoder, decoder, trained_models = train_models(train_loader, val_loader, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "5b4b2900-e1c7-4bf9-b5d6-118309296ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "287502a3-cce4-4e14-8ea7-0ed1b72ea9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LID_NSA AutoEncoder': NSAAutoEncoder(\n",
       "   (encoder): Sequential(\n",
       "     (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (7): ReLU()\n",
       "     (8): Linear(in_features=512, out_features=64, bias=True)\n",
       "   )\n",
       "   (decoder): Sequential(\n",
       "     (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (7): ReLU()\n",
       "     (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "   )\n",
       "   (NSALoss): LID_NSALoss()\n",
       "   (MSELoss): MSELoss()\n",
       " )}"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "c9f891c5-ab96-4edc-97dc-ea159e91edf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k_L64_N32'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "a91b08b8-a917-4462-a964-2fc4710ccbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19717, 64)\n",
      "(19717, 256)\n"
     ]
    }
   ],
   "source": [
    "version = config['version']\n",
    "train_loader = DataLoader(\n",
    "    train,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_with_matrix_geodesic if geodesic else collate_with_matrix,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for model_name in trained_models:\n",
    "    latent, labels = get_latent_representations(trained_models[model_name], train_loader)\n",
    "    print(latent.shape)\n",
    "    np.save(f'data/{dataset_name}/{model_name}_latent_output_{version}.npy', latent)\n",
    "    np.save(f'data/{dataset_name}/{model_name}_latent_labels_{version}.npy', labels)\n",
    "\n",
    "for model_name in trained_models:\n",
    "    latent, labels = get_output_representations(trained_models[model_name], train_loader)\n",
    "    print(latent.shape)\n",
    "    np.save(f'data/{dataset_name}/{model_name}_final_output_{version}.npy', latent)\n",
    "    np.save(f'data/{dataset_name}/{model_name}_final_labels_{version}.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "bd8a1433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840, 64)\n",
      "(3840, 256)\n"
     ]
    }
   ],
   "source": [
    "for model_name in trained_models:\n",
    "    latent, labels = get_latent_representations(trained_models[model_name], val_loader)\n",
    "    print(latent.shape)\n",
    "    np.save(f'data/{dataset_name}/{model_name}_latent_output_{version}_test.npy', latent)\n",
    "    np.save(f'data/{dataset_name}/{model_name}_latent_labels_{version}_test.npy', labels)\n",
    "\n",
    "for model_name in trained_models:\n",
    "    latent, labels = get_output_representations(trained_models[model_name], val_loader)\n",
    "    print(latent.shape)\n",
    "    np.save(f'data/{dataset_name}/{model_name}_final_output_{version}_test.npy', latent)\n",
    "    np.save(f'data/{dataset_name}/{model_name}_final_labels_{version}_test.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111eb76-3c90-4eb0-8855-b0af52b12d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafc481-ca3e-4dc4-91a8-2669eae7f66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894ecc6-20c0-4470-8efe-ca3fb0be5d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3ce31-b511-4022-80a2-21944bdc1c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
