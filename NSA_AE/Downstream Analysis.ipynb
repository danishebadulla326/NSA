{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c34cf-f129-4529-8faf-7e8fe7b359e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749e331-e7a5-424a-8b9d-997b2148ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'CIFAR-10'\n",
    "version = 'd256_K32_N32_A_v1'\n",
    "\n",
    "models = {\n",
    "    'PCA':'PCA',\n",
    "    'UMAP':'UMAP',\n",
    "    'Basic AutoEncoder':'AE',\n",
    "    'Topological AutoEncoder':'TopoAE (Moor et.al.)',\n",
    "    'RTD AutoEncoder H1':'RTD-AE',\n",
    "    'GNSA AutoEncoder':'GNSA-AE',\n",
    "    'LNSA AutoEncoder':'LNSA-AE',\n",
    "    'NSA AutoEncoder':'NSA-AE',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d66491-26fb-4921-8f8a-2d9b9916922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"COIL\" in dataset_name:\n",
    "    data = np.load(f'data/{dataset_name}/prepared/data.npy')\n",
    "else:\n",
    "    data = np.load(f'data/{dataset_name}/prepared/train_data.npy')\n",
    "data = data.reshape(data.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5d020-fcfc-4d93-a3d2-b354bad1d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_train_data = np.load(f'data/{dataset_name}/{model}_latent_output_{version}.npy')\n",
    "#latent_train_labels = np.load(f'data/{dataset_name}/prepared/train_labels.npy')\n",
    "#latent_train_labels = np.load(f'data/{dataset_name}/prepared/labels.npy')\n",
    "latent_train_labels = np.load(f'data/{dataset_name}/{model}_final_labels_{version}.npy')\n",
    "\n",
    "latent_test_data = np.load(f'data/{dataset_name}/{model}_latent_output_{version}_test.npy')\n",
    "#latent_test_labels = np.load(f'data/{dataset_name}/prepared/test_labels.npy')\n",
    "latent_test_labels = np.load(f'data/{dataset_name}/{model}_final_labels_{version}_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6620228-6f77-4d89-a282-1b9c3a7e6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent_train_data.shape[0]==latent_train_labels.shape[0])\n",
    "print(latent_test_data.shape[0]==latent_test_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6d9aa-a949-477b-8c46-fdda9a16ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "tsne_results = tsne.fit_transform(latent_train_data)\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# colormap = plt.cm.get_cmap('tab20', 20)\n",
    "# scatter = ax.scatter(tsne_results[:, 0], tsne_results[:, 1], tsne_results[:, 2], c=latent_train_labels)\n",
    "# legend = ax.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "# ax.add_artist(legend)\n",
    "# plt.title(f\"3D t-SNE Visualization for {dataset_name} with {model}\", fontsize = 20)\n",
    "# #plt.savefig(f\"{model}_{dataset_name}_tSNE.jpg\", bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd7ee4-9f71-4c8c-b65c-5e6f7224b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "colormap = plt.cm.get_cmap('tab20', 20)\n",
    "# Plot each class with a unique color\n",
    "for class_label in range(21):\n",
    "    mask = latent_train_labels == class_label\n",
    "    ax.scatter(tsne_results[mask, 0], tsne_results[mask, 1], tsne_results[mask, 2], label=f'Class {class_label}', c=[colormap(class_label)])\n",
    "\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "#ax.legend()\n",
    "\n",
    "#plt.title('3D Scatter Plot with More than 10 Classes')\n",
    "plt.savefig(f\"{model}_{dataset_name}_tSNE.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587bff6-f558-4062-894d-f2c262dc029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To plot coil dataset\n",
    "\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "colormap = plt.cm.get_cmap('tab20', 20)\n",
    "# Plot each class with a unique color\n",
    "for class_label in range(21):\n",
    "    mask = latent_train_labels == class_label\n",
    "    ax.scatter(tsne_results[mask, 0], tsne_results[mask, 1], tsne_results[mask, 2], label=f'Class {class_label}', c=[colormap(class_label)])\n",
    "\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "ax.legend()\n",
    "\n",
    "plt.title('3D Scatter Plot with More than 10 Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760de45d-8859-4238-905d-428bc8fc2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# tsne = TSNE(n_components=3, random_state=42)\n",
    "# tsne_results = tsne.fit_transform(latent_train_data)\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# scatter = ax.scatter(tsne_results[:, 0], tsne_results[:, 1], tsne_results[:, 2], c=latent_train_labels, cmap='tab10')\n",
    "# legend = ax.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "# ax.add_artist(legend)\n",
    "# plt.title(\"3D t-SNE Visualization of Latent Embeddings\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc695787-484a-48e3-8a2e-286eee39406d",
   "metadata": {},
   "source": [
    "## Sentence Similarity with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37a92c-4b23-47b0-9cfb-7c99bb5988c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://github.com/mmihaltz/word2vec-GoogleNews-vectors/raw/master/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f08b5-edb8-464c-89d9-beab0659c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load('word2vec-google-news-300')\n",
    "\n",
    "vec_king = model['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f051888-5680-43dd-b62a-426e04ca6b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b725286-edd8-4372-892e-352447842313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the STS benchmark dataset\n",
    "sts_dataset = load_dataset(\"stsb_multi_mt\",'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a652cda-db1f-4c8d-8d21-e36dfd34f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fea70-a62c-483e-ac4a-14ba7cb18c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load your Word2Vec model\n",
    "#model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Extracting words and their vectors\n",
    "words = []\n",
    "word_vectors = []\n",
    "word_to_vec_map = {}\n",
    "\n",
    "for word in model.key_to_index:\n",
    "    words.append(word)\n",
    "    word_vector = model[word]\n",
    "    word_vectors.append(word_vector)\n",
    "    word_to_vec_map[word] = word_vector\n",
    "\n",
    "# Convert word vectors to an array\n",
    "import numpy as np\n",
    "word_vectors_array = np.array(word_vectors)\n",
    "\n",
    "# Now, 'word_vectors_array' is an array of all word vectors\n",
    "# 'words' is the list of words corresponding to these vectors\n",
    "# 'word_to_vec_map' is a dictionary mapping words to their vectors\n",
    "word_dict={}\n",
    "index_dict={}\n",
    "for i,word in enumerate(words):\n",
    "    word_dict[i]=word\n",
    "    index_dict[word]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4536bfad-1425-4285-a2c3-bae1704a578a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5887e-9365-48b2-a3f6-8ae2f1e473f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_sentence_embedding(sentence, model):\n",
    "    words = sentence.split()\n",
    "    word_embeddings = [model[word] for word in words if word in model]\n",
    "    if not word_embeddings:\n",
    "        return np.zeros(model.vector_size)\n",
    "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
    "    return sentence_embedding\n",
    "\n",
    "# Example usage\n",
    "sentence_embedding = get_sentence_embedding(\"This is a test sentence.\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd47b1-2b6c-4eff-9daf-fde56756aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03cb2f9-3e15-4e2b-8057-9e1070bc4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def compute_similarity_pairs(dataset, model,space=False, index_dict=index_dict):\n",
    "    similarities = []\n",
    "    gt_similarities = []\n",
    "    for item in dataset:\n",
    "        if space==True:\n",
    "            emb1 = get_sentence_embedding_from_space(item['sentence1'], model, index_dict)\n",
    "            emb2 = get_sentence_embedding_from_space(item['sentence2'], model, index_dict)\n",
    "        else:\n",
    "            emb1 = get_sentence_embedding(item['sentence1'], model)\n",
    "            emb2 = get_sentence_embedding(item['sentence2'], model)\n",
    "        pure_sim = item['similarity_score']\n",
    "        sim = 1 - cosine(emb1, emb2)  # Cosine similarity\n",
    "        similarities.append(sim)\n",
    "        gt_similarities.append(pure_sim)\n",
    "    return gt_similarities,similarities\n",
    "\n",
    "gt_similarities,original_similarities = compute_similarity_pairs(sts_dataset['train'], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e7303-2537-459b-af8a-2510fb0f640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e52d8-5841-4896-b963-ca33e3c947ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"AE\":\"Basic AutoEncoder\",\n",
    "    \"NSA-AE\":\"NSA AutoEncoder\"\n",
    "}\n",
    "model_choice = \"AE\"\n",
    "version = 'd32'\n",
    "latent_data = np.load(f'data/word2vec/{models[model_choice]}_latent_output_{version}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b454d4-ada4-4fba-bee1-ac5b0d5e8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33812311-aebf-45d3-89ce-25c3d03b2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"AE\":\"Basic AutoEncoder\",\n",
    "    \"NSA-AE\":\"NSA AutoEncoder\"\n",
    "}\n",
    "model_choice = \"AE\"\n",
    "version = 'd32'\n",
    "latent_data = np.load(f'data/word2vec/{models[model_choice]}_latent_output_{version}.npy')\n",
    "latent_labels = np.load(f'data/word2vec/{models[model_choice]}_latent_labels_{version}.npy')\n",
    "\n",
    "final_data = np.load(f'data/word2vec/{models[model_choice]}_final_output_{version}.npy')\n",
    "final_labels = np.load(f'data/word2vec/{models[model_choice]}_final_labels_{version}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa54ec-66e4-4a40-b772-9fe60637aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_sentence_embedding_from_space(sentence, embedding_space,index_dict):\n",
    "    words = sentence.split()\n",
    "    word_embeddings = [embedding_space[index_dict[word]] for word in words if word in index_dict]\n",
    "    if not word_embeddings:\n",
    "        return np.zeros(embedding_space[0].shape[0])\n",
    "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
    "    return sentence_embedding\n",
    "\n",
    "# Example usage\n",
    "sentence_embedding = get_sentence_embedding_from_space(\"This is a test sentence.\", latent_data, index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c7b99-7593-4bad-a7c2-0a53e4c251b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce34c56-c525-4243-83df-e47efd3a2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_similarities,reconstructed_similarities = compute_similarity_pairs(sts_dataset['train'], latent_data,space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8015408-67b6-4c08-853d-52fec4ab8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reconstructed_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1b519-0fd1-439e-a5fc-ef9fea915b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Ground truth scores\n",
    "ground_truth_scores = [item['similarity_score'] for item in sts_dataset['train']]\n",
    "\n",
    "# Pearson correlation for original embeddings\n",
    "pearson_corr_original = pearsonr(original_similarities, ground_truth_scores)\n",
    "print(f\"Pearson Correlation (Original): {pearson_corr_original}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_reduced = pearsonr(reconstructed_similarities, ground_truth_scores)\n",
    "print(f\"Pearson Correlation (Reduced): {pearson_corr_reduced}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a516dfc-8886-4acb-9a45-82bff35b16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(original_similarities, reconstructed_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5db4b9-4a87-4483-bf36-878fd537c30f",
   "metadata": {},
   "source": [
    "## GNN Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5714d1f-c762-4fc0-beec-996033a7a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.datasets import Amazon\n",
    "from torch_geometric.transforms.random_node_split import RandomNodeSplit\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from IPython.display import Javascript  # Restrict height of output cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2468a6c-e937-4913-afa0-b095b5108a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid, Flickr, Amazon\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset_name=\"Amazon\"\n",
    "\n",
    "if dataset_name=='Flickr':\n",
    "    transform = Compose([\n",
    "        #NormalizeFeatures(),\n",
    "        RandomNodeSplit('train_rest',num_val = 2000, num_test = 10000)\n",
    "    ])\n",
    "    dataset = Flickr(root='data/Flickr', \\\n",
    "                     transform =transform)\n",
    "elif dataset_name=='Amazon':\n",
    "    transform = Compose([\n",
    "        #NormalizeFeatures(),\n",
    "        RandomNodeSplit('train_rest',num_val = 1000, num_test = 3000)\n",
    "    ])\n",
    "    dataset = Amazon(root='data/Amazon', name='Computers', \\\n",
    "                     transform =transform)\n",
    "\n",
    "elif dataset_name in ['Cora', 'Citeseer', 'Pubmed']:\n",
    "    # For Planetoid datasets, the standard split is already defined\n",
    "    dataset = Planetoid(root=f'data/{dataset_name}', name=dataset_name)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869109a-b6e5-48cd-ad4a-18a58d2e33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_edge_index = data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be412a2b-7579-4899-b2da-ffd12d2d1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631447d-94fa-4823-80e9-3c19897f8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edge_index = negative_sampling(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262f767-38e0-4b45-872e-de97fd5fbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell if you already have embeddings from GNN_Analysis\n",
    "#!mkdir data/LinkPrediction/Amazon\n",
    "#!cp ../GNN_analysis/model_data/Amazon/GCN/LP_3_200.npz data/LinkPrediction/Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f713fa-14f4-4559-ae4b-f5cfaee7c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(f'data/LinkPrediction/{dataset_name}/LP_3_200.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b14c0-1eaf-464a-a2ad-0b36a3cb9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict(features)\n",
    "features['conv1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56476d0c-743b-45e8-8f6b-e408d281ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    perfs = []\n",
    "    for prefix in [\"val\", \"test\"]:\n",
    "        pos_edge_index = data[f'{prefix}_pos_edge_index']\n",
    "        neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
    "\n",
    "        z = model.encode(data.x, data.train_pos_edge_index) # encode train\n",
    "        link_logits = model.decode(z, pos_edge_index, neg_edge_index) # decode test or val\n",
    "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
    "        \n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index) # get link\n",
    "        \n",
    "        perfs.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score\n",
    "    return perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244841b5-b5b9-4d1d-8a98-08a206e1a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = features['conv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4033235-f0f7-489d-879c-cfefe83b413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c348755-787c-46e3-9312-472fa25d804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # \"AE\":\"Basic AutoEncoder\",\n",
    "    # \"NSA-AE\":\"NSA AutoEncoder\",\n",
    "    # \"RTD-AE\":\"RTD AutoEncoder H1\",\n",
    "    'GNSA-AE':'GNSA AutoEncoder',\n",
    "    'LNSA-AE':'LNSA AutoEncoder',\n",
    "    'NSA-AE':'NSA AutoEncoder',\n",
    "\n",
    "}\n",
    "model_choice = \"GNSA-AE\"\n",
    "version = 'd64_2'\n",
    "latent_data = np.load(f'data/LinkPrediction/{dataset_name}/{models[model_choice]}_latent_output_{version}.npy')\n",
    "latent_labels = np.load(f'data/LinkPrediction/{dataset_name}/{models[model_choice]}_latent_labels_{version}.npy')\n",
    "\n",
    "final_data = np.load(f'data/LinkPrediction/{dataset_name}/{models[model_choice]}_final_output_{version}.npy')\n",
    "final_labels = np.load(f'data/LinkPrediction/{dataset_name}/{models[model_choice]}_final_labels_{version}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8f799-75a0-419c-894f-e9109ee515bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data.shape)\n",
    "print(latent_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c064d-6b44-4ef6-9a5c-335c7eee328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    # returns a tensor:\n",
    "    # [1,1,1,1,...,0,0,0,0,0,..] with the number of ones is equel to the length of pos_edge_index\n",
    "    # and the number of zeros is equal to the length of neg_edge_index\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "def generate_prediction_score(embeddings, pos_edge_index, neg_edge_index):\n",
    "    edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
    "    print(edge_index.shape)\n",
    "    logits = (embeddings[edge_index[0]] * embeddings[edge_index[1]]).sum(dim=-1)  # dot product \n",
    "    \n",
    "    print(logits.shape)\n",
    "    link_probs = logits.sigmoid() # apply sigmoid\n",
    "    #link_probs = np.array(link_probs)\n",
    "    #link_probs = (link_probs>=0.5).astype(int)\n",
    "    #print(Counter(link_probs))\n",
    "    link_labels = get_link_labels(pos_edge_index, neg_edge_index) # get link\n",
    "    print(link_labels.shape)\n",
    "    print(Counter(np.array(link_labels.cpu())))\n",
    "    return roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
    "    #return sum(np.array(link_labels.cpu()) == np.array(link_probs)) #compute roc_auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b06f54-2842-4d14-8e9e-c5787466b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prediction_score(torch.tensor(latent_data), pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461c04b-ce43-4b69-9f6d-6f7021c1e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prediction_score(torch.tensor(final_data), pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4493c60-8465-45eb-88b8-b00d40d21012",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prediction_score(torch.tensor(original_data), pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883bc67b-b7f0-4bdf-91d6-1fed66bc259e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
