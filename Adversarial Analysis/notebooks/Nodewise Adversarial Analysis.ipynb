{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import gb\n",
    "from gb.exutil import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42772178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gb.model import GraphSequential, PreprocessA, PreprocessX, PreprocessAUsingXMetric, GCN, RGCN, ProGNN, GNNGuard, \\\n",
    "    GRAND, MLP, SoftMedianPropagation\n",
    "from gb.pert import sp_edge_diff_matrix, sp_feat_diff_matrix\n",
    "from gb.torchext import mul\n",
    "from gb import metric, preprocess\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cora\"\n",
    "A, X, y = gb.data.get_dataset(dataset)\n",
    "N, D = X.shape\n",
    "C = y.max().item() + 1\n",
    "train_nodes, val_nodes, test_nodes = gb.data.get_splits(y)[0]  # [0] = select first split\n",
    "\n",
    "A = A.cuda()\n",
    "X = X.cuda()\n",
    "y = y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_rate = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92497aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = int(ptb_rate * (A.cpu().numpy().sum() // 2))\n",
    "budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64cc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_value = str(int(ptb_rate*100))\n",
    "ptb_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fccd43-3e76-4949-b71d-cc8dd435ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = {}\n",
    "accuracy_dict['GCN']={}\n",
    "accuracy_dict['GRAND']={}\n",
    "accuracy_dict['GNNGuard']={}\n",
    "accuracy_dict['GCNSVD']={}\n",
    "accuracy_dict['ProGNN']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff09852e-6bf6-47a5-bb34-9fe0d37f076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc6d54-7ff1-401a-b2a7-536ea9121806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.count_nonzero(A.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095327c-a578-4a30-81ec-8dd831f276d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b48a6-644f-4d3c-8ca9-5f94beb2b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class NSALoss_v2(nn.Module):\n",
    "    def __init__(self,node_list=torch.tensor([]), **kwargs):\n",
    "        super().__init__()\n",
    "        self.node_list = torch.tensor([])\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        # normA1 = torch.max(torch.sqrt(torch.sum(x**2,axis=1)))\n",
    "        # normA2 = torch.max(torch.sqrt(torch.sum(z**2,axis=1)))   \n",
    "        normA1 = torch.quantile(torch.sqrt(torch.sum(x**2,axis=1)),0.98)\n",
    "        normA2 = torch.quantile(torch.sqrt(torch.sum(z**2,axis=1)),0.98)\n",
    "        \n",
    "        A1_pairwise = torch.cdist(x,x)    # compute pairwise dist\n",
    "        A2_pairwise = torch.cdist(z,z)    # compute pairwise dist\n",
    "        \n",
    "        A1_pairwise = A1_pairwise/(2*normA1)\n",
    "        A2_pairwise = A2_pairwise/(2*normA2)\n",
    "        \n",
    "        loss = torch.abs(A2_pairwise - A1_pairwise)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf6ede0-1c25-4368-82a4-9afad5864e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gb.sims import *\n",
    "criterion = NSALoss()\n",
    "criterion_v2 = NSALoss_v2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9975e",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "fit_kwargs = dict(lr=1e-2, weight_decay=5e-4)\n",
    "\n",
    "def make_model():\n",
    "    return gb.model.GCN(n_feat=D, n_class=C, hidden_dims=[64], dropout=0.5).cuda()\n",
    "\n",
    "aux_model = make_model()\n",
    "aux_model.fit((A, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364534d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_accuracy = gb.metric.accuracy(aux_model(A, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GCN']['clean']=clean_accuracy\n",
    "\n",
    "print(\"Clean test acc:   \", clean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals = aux_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381db2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in clean_vals.items():\n",
    "    print(v.shape)\n",
    "    clean_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8d0fc-6c4b-49fb-a694-6f28e96f15f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2 = {}\n",
    "for k,v in clean_vals.items():\n",
    "    clean_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd716315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez(f'feature_vals/gcn_clean_{ptb_value}.npz', **clean_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed80322",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Poisoning global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96813024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_pert = A + A_flip * (1 - 2 * A)\n",
    "\n",
    "    ########### Meta-Attack w/ Adam ##########\n",
    "    model = make_model()\n",
    "    model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False,\\\n",
    "              **fit_kwargs, differentiable=A_pert.requires_grad)\n",
    "    ##########################################\n",
    "\n",
    "    scores = model(A_pert, X)\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()\n",
    "\n",
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### PGD for Meta-Attack ##########\n",
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, \\\n",
    "                                      base_lr=0.01, grad_clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5627bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67f602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Adversarial edges:\", pert.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_model = make_model()\n",
    "pois_model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "pois_accuracy = gb.metric.accuracy(pois_model(A_pert, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GCN']['pois']=pois_accuracy\n",
    "\n",
    "print(\"Poisoned test acc:\", pois_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_vals=pois_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in pois_vals.items():\n",
    "    print(v.shape)\n",
    "    pois_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa20daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('feature_vals/gcn_gp_'+ptb_value+'.npz', **pois_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb144b",
   "metadata": {},
   "source": [
    "### Evasion global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_pert = A + A_flip * (1 - 2 * A)\n",
    "\n",
    "    ############### Aux-Attack ###############\n",
    "    model = aux_model\n",
    "\n",
    "    scores = model(A_pert, X)\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### PGD for Aux-Attack ###########\n",
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn,\\\n",
    "                                      base_lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4541f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)\n",
    "print(\"Adversarial edges:\", pert.shape[0])\n",
    "evas_accuracy = gb.metric.accuracy(aux_model(A_pert, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GCN']['evas'] = evas_accuracy\n",
    "\n",
    "print(\"Evasion test acc: \", evas_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcf281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux_model(A_pert,X)\n",
    "evasion_vals=aux_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d435668",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in evasion_vals.items():\n",
    "    print(v.shape)\n",
    "    evasion_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206b82d-0741-4acd-a32b-4fdd3553db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals2 = {}\n",
    "for k,v in evasion_vals.items():\n",
    "    evasion_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez('feature_vals/gcn_ge_'+ptb_value+'.npz', **evasion_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e873e-f5e2-4c58-a4fe-72da3b38b177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3888bea4-64f8-45f1-ad8c-ff2906fb6973",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Node Degree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5e476-f698-4534-831d-f87a8fe64307",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae1381-a218-4170-8fea-3a76abf3b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714efe62-c077-4682-b1bb-29043aefd543",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dcc571-f180-4bac-b54e-ed9c85c156e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a0e58-182f-452a-8eca-9afbea1f15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(clean_vals2['conv1'],evasion_vals2['conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfc883-7c45-48d7-8304-aeec37816fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf309a9-eb81-4975-9ab8-02c5efebf3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how many edges were changed for each node\n",
    "edge_change = torch.abs(A - A_pert).sum(dim=1).cpu()\n",
    "print(sum(edge_change))\n",
    "print(len(torch.nonzero(edge_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b1872-65ee-40f9-be9f-1f207d157a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how much the degree changed for each node\n",
    "degree_change = torch.abs(A.sum(dim=1) - A_pert.sum(dim=1)).cpu()\n",
    "print(sum(degree_change))\n",
    "print(len(torch.nonzero(degree_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3116d-262c-44ae-852a-f912c89d0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Ground truth scores\n",
    "\n",
    "# Pearson correlation for original embeddings\n",
    "pearson_corr_edge = pearsonr(nodewise_nsa, edge_change)\n",
    "print(f\"Pearson Correlation (edge): {pearson_corr_edge}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_degree = pearsonr(nodewise_nsa, degree_change)\n",
    "print(f\"Pearson Correlation (degree): {pearson_corr_degree}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_high = pearsonr(degree_change, edge_change)\n",
    "print(f\"Pearson Correlation (high): {pearson_corr_high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5df9f0-1dea-4d1d-ab9a-63753d540be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edge_changes = torch.sort(edge_change, descending=True)[1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a78e6-5fb3-4149-8e7b-167825701fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_change[max_edge_changes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32270b8-9abc-45ad-b518-6a8a890b54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in max_edge_changes:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0]\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55f146-29e3-43a6-b484-ddad997eb218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "values = edge_change[max_edge_changes]\n",
    "percentiles = nodewise_nsa[max_edge_changes]\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "\n",
    "\n",
    "# Plotting the column chart\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Values', color=color)\n",
    "ax1.bar(range(len(values)), values, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Create a second y-axis for the percentiles\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Percentiles', color=color)\n",
    "ax2.plot(range(len(percentiles)), percentiles, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81844e63-4560-4bf4-9813-a00feba10caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_percentile  = deepcopy(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048627a-8383-4c2c-a8c8-d3990fb7dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa_gcn = deepcopy(nodewise_nsa[max_edge_changes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a78bb-9ba8-4759-87b0-a3dd5abce4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8d6d4c2-71f9-4795-bd6b-8d94910f5e55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aee80a-70b0-423f-b27a-0b4e5533336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_counts = []\n",
    "evasion_counts = []\n",
    "\n",
    "clean_misclassify = []\n",
    "evasion_misclassify = []\n",
    "for threshold in thresholds:\n",
    "    boundary_indices_clean = np.where(np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "    boundary_indices_evasion = np.where(np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]\n",
    "    clean_counts.append(boundary_indices_clean.shape[0])\n",
    "    evasion_counts.append(boundary_indices_evasion.shape[0])\n",
    "\n",
    "    if threshold==0:\n",
    "        clean_misclassify.append(0)\n",
    "        evasion_misclassify.append(0)\n",
    "        continue\n",
    "    #Calculate misclassified nodes at this threshold\n",
    "    misclassify_count_clean=np.count_nonzero(np.argmax(probabilities_clean[boundary_indices_clean],axis=-1) != y[boundary_indices_clean].cpu().numpy())\n",
    "    misclassify_count_evasion=np.count_nonzero(np.argmax(probabilities_evasion[boundary_indices_evasion],axis=-1) != y[boundary_indices_evasion].cpu().numpy())\n",
    "    #print(misclassify_count_clean)\n",
    "    clean_misclassify.append(misclassify_count_clean)\n",
    "    evasion_misclassify.append(misclassify_count_evasion)\n",
    "\n",
    "clean_counts=np.diff(clean_counts)\n",
    "evasion_counts=np.diff(evasion_counts)\n",
    "clean_misclassify = np.diff(clean_misclassify)\n",
    "evasion_misclassify = np.diff(clean_misclassify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afa812-7ef3-496b-87b7-21981a14bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "values1 = clean_counts[0:7]\n",
    "values2 = evasion_counts[0:7]\n",
    "plt.plot(values1)\n",
    "plt.plot(values2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ea865-5801-47c0-9714-a094db37e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "boundary_indices_clean = np.where(\\\n",
    "    np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "\n",
    "boundary_indices_evasion = np.where(\\\n",
    "    np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50e467-9da9-43d4-81e5-e814070dee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a84f0-e49b-453b-ab47-a8995a74f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodewise_nsa = nodewise_nsa[boundary_indices_evasion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f03a30-b790-4fd5-840e-ce08a5fbae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in boundary_indices_evasion:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0][0]\n",
    "    #print(position)\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed635c2-a9af-44cb-9677-258f74ee2445",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa[boundary_indices_evasion].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580900a7-534e-4786-aa39-1ace91c5eb78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boundary_indices_clean.shape)\n",
    "print(boundary_indices_evasion.shape)\n",
    "print(np.mean(percentiles))\n",
    "print(torch.mean(nodewise_nsa[boundary_indices_evasion]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01ca9c-d7d1-4c0d-9e88-f55ea9e6ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_confidence=np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2]\n",
    "evasion_confidence=np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3faa76-91e1-49bd-bfd9-7c2298b25e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_correct_indices=np.argmax(probabilities_clean,axis=-1) == y.cpu().numpy()\n",
    "clean_correct_indices = np.where(clean_correct_indices==True)[0]\n",
    "evasion_correct_indices=np.argmax(probabilities_evasion,axis=-1) == y.cpu().numpy()\n",
    "evasion_correct_indices = np.where(evasion_correct_indices==True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838068e-3e50-4f72-a1b1-a5b84d6676ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_ec = evasion_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f121d-1a22-4d50-a721-8fae1e894234",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "print(np.count_nonzero((clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero((clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be9644-d822-44c6-be25-7644a4e7b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_indices = np.argsort(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])[::-1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5afaa-26f8-4e93-b26e-095cf9a51208",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa.cpu().numpy()[worst_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c11ff-86db-456f-b265-df17d1b3560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_nodewise_nsa = nodewise_nsa.cpu().numpy()[worst_indices]\n",
    "np.mean(gcn_nodewise_nsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a584396",
   "metadata": {},
   "source": [
    "## GCN-SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95bafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 50\n",
    "fit_kwargs = dict(lr=1e-2, weight_decay=5e-4)\n",
    "\n",
    "def make_model():\n",
    "    return gb.model.GraphSequential(OrderedDict(\n",
    "        low_rank=gb.model.PreprocessA(lambda A: gb.preprocess.low_rank(A, rank)),\n",
    "        gcn=gb.model.GCN(n_feat=D, n_class=C, hidden_dims=[64], dropout=0.5)\n",
    "    )).cuda()\n",
    "\n",
    "aux_model = make_model()\n",
    "aux_model.fit((A, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "\n",
    "A_low_rank = aux_model.low_rank(A)\n",
    "A_weights = gb.metric.eigenspace_alignment(A, rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60661d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_accuracy = gb.metric.accuracy(aux_model(A, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GCNSVD']['clean']=clean_accuracy\n",
    "\n",
    "print(\"Clean test acc:   \", clean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f74ee6-8e30-4ed7-a4f5-199b423f806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals = aux_model.gcn.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b26304",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in clean_vals.items():\n",
    "    print(v.shape)\n",
    "    clean_vals[k]=deepcopy(v.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648ab2e-c061-4870-8ad2-2c3a145970bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679752e2-9af6-4bee-96c4-1f9021f1c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2 = {}\n",
    "for k,v in clean_vals.items():\n",
    "    clean_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d70c4-ee97-4c63-8888-de90bd945773",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0984fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez(f'feature_vals/gcnsvd_clean_{ptb_value}.npz', **clean_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6dcef4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Poisoning global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633aab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "\n",
    "    ############# w/ weights #############\n",
    "    #A_diff = A_diff * A_weights\n",
    "    ######################################\n",
    "\n",
    "    A_pert = A_low_rank + A_diff\n",
    "\n",
    "\n",
    "    ############# Meta-Attack ############\n",
    "    model = make_model().sub(exclude=[\"low_rank\"])\n",
    "    model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs, differentiable=A_pert.requires_grad)\n",
    "    ######################################\n",
    "\n",
    "    scores = model(A_pert, X)\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3949c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## PGD for Meta-Attack ##########\n",
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn,\\\n",
    "                                      base_lr=0.1, grad_clip=0.1)\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_model = make_model()\n",
    "pois_model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "pois_accuracy = gb.metric.accuracy(pois_model(A_pert, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GCNSVD']['pois']=pois_accuracy\n",
    "\n",
    "print(\"Poisoned test acc:\", pois_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8eb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pois_vals=pois_model.gcn.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d045cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in pois_vals.items():\n",
    "    print(v.shape)\n",
    "    pois_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('feature_vals/gcnsvd_gp_'+ptb_value+'.npz', **pois_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de3097",
   "metadata": {},
   "source": [
    "### Evasion global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6eeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "\n",
    "    A_pert = A_low_rank + A_diff\n",
    "\n",
    "    ############# Aux-Attack #############\n",
    "    model = aux_model.sub(exclude=[\"low_rank\"])\n",
    "\n",
    "    scores = model(A_pert, X)\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()\n",
    "\n",
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3481b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### PGD for Aux-Attack ###########\n",
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn,\\\n",
    "                                      loss_fn, base_lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f53efa-1c1a-4fe3-bed6-09d48397c292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86facf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)\n",
    "print(\"Adversarial edges:\", pert.shape[0])\n",
    "evas_accuracy = gb.metric.accuracy(aux_model(A_pert, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GCNSVD']['evas']=evas_accuracy\n",
    "\n",
    "print(\"Evasion test acc: \", evas_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55470f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_model(A_pert,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_model(A_pert,X)\n",
    "evasion_vals=aux_model.gcn.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa00810",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in evasion_vals.items():\n",
    "    print(v.shape)\n",
    "    evasion_vals[k]=deepcopy(v.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc138366-9dc6-41d5-a616-6fa822bfd402",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals2 = {}\n",
    "for k,v in evasion_vals.items():\n",
    "    evasion_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d70987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez('feature_vals/gcnsvd_ge_'+ptb_value+'.npz', **evasion_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece980f-d4d2-423e-97d3-5c6b77e94828",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Node Degree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831fdb9-f310-4024-a0a2-2aee805c6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f278f-73f9-451f-8aad-ec627ba1432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how many edges were changed for each node\n",
    "edge_change = torch.abs(A - A_pert).sum(dim=1).cpu()\n",
    "print(sum(edge_change))\n",
    "print(len(torch.nonzero(edge_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77aa79a-aa6e-47cc-9399-28cafb650b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how much the degree changed for each node\n",
    "degree_change = torch.abs(A.sum(dim=1) - A_pert.sum(dim=1)).cpu()\n",
    "print(sum(degree_change))\n",
    "print(len(torch.nonzero(degree_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2745837-7893-4286-8a22-3bea13923f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Ground truth scores\n",
    "\n",
    "# Pearson correlation for original embeddings\n",
    "pearson_corr_edge = pearsonr(nodewise_nsa, edge_change)\n",
    "print(f\"Pearson Correlation (edge): {pearson_corr_edge}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_degree = pearsonr(nodewise_nsa, degree_change)\n",
    "print(f\"Pearson Correlation (degree): {pearson_corr_degree}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_high = pearsonr(degree_change, edge_change)\n",
    "print(f\"Pearson Correlation (high): {pearson_corr_high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e4070-1fad-4fad-b8cc-66179f35598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edge_changes = torch.sort(edge_change, descending=True)[1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b25d0-0be3-4217-8f52-9371f42c970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_change[max_edge_changes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d8367-7995-4e74-96aa-f9a29717d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in max_edge_changes:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0]\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940e2e4-4008-4e59-92ae-cbeb2d08d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "values = edge_change[max_edge_changes]\n",
    "percentiles = nodewise_nsa[max_edge_changes]\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "\n",
    "\n",
    "# Plotting the column chart\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Values', color=color)\n",
    "ax1.bar(range(len(values)), values, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Create a second y-axis for the percentiles\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Percentiles', color=color)\n",
    "ax2.plot(range(len(percentiles)), percentiles, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043ef41-1770-4e08-8983-c0314a538923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svd_percentile  = deepcopy(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a0f0a3-f8de-4cb9-ae60-6b21d6027191",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa_svd = deepcopy(nodewise_nsa[max_edge_changes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf250e-c0e3-4d9e-b65a-b6f536aad9e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068e016-8c25-4918-b171-36269cf39f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_counts = []\n",
    "evasion_counts = []\n",
    "\n",
    "clean_misclassify = []\n",
    "evasion_misclassify = []\n",
    "for threshold in thresholds:\n",
    "    boundary_indices_clean = np.where(np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "    boundary_indices_evasion = np.where(np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]\n",
    "    clean_counts.append(boundary_indices_clean.shape[0])\n",
    "    evasion_counts.append(boundary_indices_evasion.shape[0])\n",
    "\n",
    "    if threshold==0:\n",
    "        clean_misclassify.append(0)\n",
    "        evasion_misclassify.append(0)\n",
    "        continue\n",
    "    #Calculate misclassified nodes at this threshold\n",
    "    misclassify_count_clean=np.count_nonzero(np.argmax(probabilities_clean[boundary_indices_clean],axis=-1) != y[boundary_indices_clean].cpu().numpy())\n",
    "    misclassify_count_evasion=np.count_nonzero(np.argmax(probabilities_evasion[boundary_indices_evasion],axis=-1) != y[boundary_indices_evasion].cpu().numpy())\n",
    "    #print(misclassify_count_clean)\n",
    "    clean_misclassify.append(misclassify_count_clean)\n",
    "    evasion_misclassify.append(misclassify_count_evasion)\n",
    "\n",
    "clean_counts=np.diff(clean_counts)\n",
    "evasion_counts=np.diff(evasion_counts)\n",
    "clean_misclassify = np.diff(clean_misclassify)\n",
    "evasion_misclassify = np.diff(clean_misclassify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a11c4-8805-4d0a-9014-80cc27e2bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "values1 = clean_counts[0:7]\n",
    "values2 = evasion_counts[0:7]\n",
    "plt.plot(values1)\n",
    "plt.plot(values2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585d334-c8e2-46b0-9799-8339df9257e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "boundary_indices_clean = np.where(\\\n",
    "    np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "\n",
    "boundary_indices_evasion = np.where(\\\n",
    "    np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631c122-b1c9-4ad4-8650-fc8f7d25fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc3761-fdce-4cde-9129-f0520ce109fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodewise_nsa = nodewise_nsa[boundary_indices_evasion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52beecd1-5dad-44ba-8fbd-03471ffbf72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in boundary_indices_evasion:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0][0]\n",
    "    #print(position)\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f1cc4-9965-4e86-9c60-5421a9bb777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa[boundary_indices_evasion].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20ea2b-5dec-4ab5-a9f4-32b08c55c5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab133e0-a515-4d4f-a6ed-ed29461fbdaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boundary_indices_clean.shape)\n",
    "print(boundary_indices_evasion.shape)\n",
    "print(np.mean(percentiles))\n",
    "print(torch.mean(nodewise_nsa[boundary_indices_evasion]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3687ed-4bd3-406d-bc14-0454938210d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_confidence=np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2]\n",
    "evasion_confidence=np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533d869-bd48-46be-b4c7-51de7ff621e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_ec = evasion_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a38e74-56c8-4f7c-ad34-e57cfbcf25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_correct_indices=np.argmax(probabilities_clean,axis=-1) == y.cpu().numpy()\n",
    "clean_correct_indices = np.where(clean_correct_indices==True)[0]\n",
    "evasion_correct_indices=np.argmax(probabilities_evasion,axis=-1) == y.cpu().numpy()\n",
    "evasion_correct_indices = np.where(evasion_correct_indices==True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8ecb8-7ddd-4d30-be68-b66e94cd9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_correct_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aae6eb-3276-4f0e-84a2-4ea67cfc8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "print(np.count_nonzero((clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero((clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86259c2-65c6-40ae-890e-67ff24fffa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_indices = np.argsort(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])[::-1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cffa8-22ea-4071-8b8d-20cdbd597f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa.cpu().numpy()[worst_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc270fea-6750-4cdd-bc8f-45109e4c4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_nodewise_nsa = nodewise_nsa.cpu().numpy()[worst_indices]\n",
    "np.mean(svd_nodewise_nsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc89969-2757-4189-8d9d-2c3ec626ad32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boundary_indices_clean.shape)\n",
    "print(boundary_indices_evasion.shape)\n",
    "print(np.mean(percentiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09b4ea",
   "metadata": {},
   "source": [
    "## GNNGuard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46862f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 50\n",
    "fit_kwargs = dict(lr=1e-2, weight_decay=5e-4)\n",
    "\n",
    "def make_model(div_limit=1e-6):\n",
    "    return gb.model.GNNGuard(n_feat=D, n_class=C, hidden_dims=[64], dropout=0.5, div_limit=div_limit).cuda()\n",
    "\n",
    "aux_model = make_model()\n",
    "aux_model.fit((A, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1ace6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_accuracy = gb.metric.accuracy(aux_model(A, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GNNGuard']['clean']=clean_accuracy\n",
    "\n",
    "print(\"Clean test acc:   \", clean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803c6cc-cc41-44a5-a1b6-fe89a1469695",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals = aux_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f31d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in clean_vals.items():\n",
    "    print(v.shape)\n",
    "    clean_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38df68-4e8f-4e01-9c50-efdd3737c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2 = {}\n",
    "for k,v in clean_vals.items():\n",
    "    clean_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d4712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez(f'feature_vals/gnnguard_clean_{ptb_value}.npz', **clean_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ebbd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Poisoning global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fd582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "    A_pert = A + A_diff\n",
    "\n",
    "    ########## w/ real div_limit #########\n",
    "    alteration = dict()\n",
    "    ######################################\n",
    "\n",
    "    ############# Meta-Attack ############\n",
    "    model = make_model(**alteration)\n",
    "    model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs, max_epochs=50, differentiable=A_pert.requires_grad)\n",
    "    scores = model(A_pert, X)\n",
    "    ######################################\n",
    "\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28020302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn,\\\n",
    "                                      base_lr=0.1, grad_clip=0.1)\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_model = make_model()\n",
    "pois_model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "pois_accuracy = gb.metric.accuracy(pois_model(A_pert, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GNNGuard']['pois']=pois_accuracy\n",
    "\n",
    "print(\"Poisoned test acc:\", pois_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_vals=pois_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c632d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in pois_vals.items():\n",
    "    print(v.shape)\n",
    "    pois_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('feature_vals/gnnguard_gp_'+ptb_value+'.npz', **pois_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d9268",
   "metadata": {},
   "source": [
    "### Evasion global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14cdf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "    A_pert = A + A_diff\n",
    "\n",
    "    ########## w/ real div_limit #########\n",
    "    alteration = dict()\n",
    "\n",
    "    ############# Aux-Attack #############\n",
    "    with gb.model.changed_fields(aux_model, **alteration):\n",
    "        scores = aux_model(A_pert, X)\n",
    "\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()\n",
    "\n",
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a4555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.1)\n",
    "\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)\n",
    "print(\"Adversarial edges:\", pert.shape[0])\n",
    "evas_accuracy = gb.metric.accuracy(aux_model(A_pert, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GNNGuard']['evas']=evas_accuracy\n",
    "\n",
    "print(\"Evasion test acc: \", evas_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b69731",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_model(A_pert,X)\n",
    "evasion_vals=aux_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7700204-5039-4077-a49a-dab5f11fdb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in evasion_vals.items():\n",
    "    print(v.shape)\n",
    "    evasion_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6ca54-90a9-47c0-ac26-56b50ba46711",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals2 = {}\n",
    "for k,v in evasion_vals.items():\n",
    "    evasion_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez('feature_vals/gnnguard_ge_'+ptb_value+'.npz', **evasion_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd0da8-379a-4a69-952e-23f5701eb1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "705ef932-99bd-4f13-a5d0-0f70e6da0efa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Node Degree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87309204-88a3-47be-ba34-6ee7add7623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(clean_vals2['conv1'],evasion_vals2['conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c58954-05eb-4eb2-a043-9bbf8d5225c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452534b-002f-4282-bb47-07ac0ecd3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how many edges were changed for each node\n",
    "edge_change = torch.abs(A - A_pert).sum(dim=1).cpu()\n",
    "print(sum(edge_change))\n",
    "print(len(torch.nonzero(edge_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681cb815-aa86-44c7-a95b-0b6b11392fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how much the degree changed for each node\n",
    "degree_change = torch.abs(A.sum(dim=1) - A_pert.sum(dim=1)).cpu()\n",
    "print(sum(degree_change))\n",
    "print(len(torch.nonzero(degree_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d804c0-8854-492b-821e-c805a7d27368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Ground truth scores\n",
    "\n",
    "# Pearson correlation for original embeddings\n",
    "pearson_corr_edge = pearsonr(nodewise_nsa, edge_change)\n",
    "print(f\"Pearson Correlation (edge): {pearson_corr_edge}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_degree = pearsonr(nodewise_nsa, degree_change)\n",
    "print(f\"Pearson Correlation (degree): {pearson_corr_degree}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_high = pearsonr(degree_change, edge_change)\n",
    "print(f\"Pearson Correlation (high): {pearson_corr_high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee32b94-33f5-48d8-b920-de60336e29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edge_changes = torch.sort(edge_change, descending=True)[1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10cc35-3f7b-43ec-a6ae-4705b0ad3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_change[max_edge_changes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520c5b9-8feb-4d25-b5bb-9b27b4f9e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in max_edge_changes:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0]\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49586cb-217d-477a-afa2-49c445b53cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "values = edge_change[max_edge_changes]\n",
    "percentiles = nodewise_nsa[max_edge_changes] \n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "\n",
    "\n",
    "# Plotting the column chart\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Values', color=color)\n",
    "ax1.bar(range(len(values)), values, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Create a second y-axis for the percentiles\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Percentiles', color=color)\n",
    "ax2.plot(range(len(percentiles)), percentiles, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c64b5-8dff-466b-ad9a-8681f7ff1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa_guard = deepcopy(nodewise_nsa[max_edge_changes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17754d-9edd-4d3f-995c-932ced16e88b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbebfa-e0bf-4e01-b8a7-7e79b96772be",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_counts = []\n",
    "evasion_counts = []\n",
    "\n",
    "clean_misclassify = []\n",
    "evasion_misclassify = []\n",
    "for threshold in thresholds:\n",
    "    boundary_indices_clean = np.where(np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "    boundary_indices_evasion = np.where(np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]\n",
    "    clean_counts.append(boundary_indices_clean.shape[0])\n",
    "    evasion_counts.append(boundary_indices_evasion.shape[0])\n",
    "\n",
    "    if threshold==0:\n",
    "        clean_misclassify.append(0)\n",
    "        evasion_misclassify.append(0)\n",
    "        continue\n",
    "    #Calculate misclassified nodes at this threshold\n",
    "    misclassify_count_clean=np.count_nonzero(np.argmax(probabilities_clean[boundary_indices_clean],axis=-1) != y[boundary_indices_clean].cpu().numpy())\n",
    "    misclassify_count_evasion=np.count_nonzero(np.argmax(probabilities_evasion[boundary_indices_evasion],axis=-1) != y[boundary_indices_evasion].cpu().numpy())\n",
    "    #print(misclassify_count_clean)\n",
    "    clean_misclassify.append(misclassify_count_clean)\n",
    "    evasion_misclassify.append(misclassify_count_evasion)\n",
    "\n",
    "clean_counts=np.diff(clean_counts)\n",
    "evasion_counts=np.diff(evasion_counts)\n",
    "clean_misclassify = np.diff(clean_misclassify)\n",
    "evasion_misclassify = np.diff(clean_misclassify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b6070-7d35-4e8c-b63a-4635ec0483a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "values1 = clean_counts[0:7]\n",
    "values2 = evasion_counts[0:7]\n",
    "plt.plot(values1)\n",
    "plt.plot(values2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193dc5a1-1283-40fa-a14f-fa507f0613d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "boundary_indices_clean = np.where(\\\n",
    "    np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "\n",
    "boundary_indices_evasion = np.where(\\\n",
    "    np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed5b5d-77b9-4457-8498-e9b944746f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6f93c-fabf-4e88-bc48-4fcfa88e14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodewise_nsa = nodewise_nsa[boundary_indices_evasion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c40184-350a-4180-855e-a033321e004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in boundary_indices_evasion:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0][0]\n",
    "    #print(position)\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d85235-7d57-47ba-9b33-1b1ac54238c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa[boundary_indices_evasion].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ccf47a-4ff7-44f2-8ba4-0389e22a7a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26f049-1294-4d37-8166-d76ecd98808a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boundary_indices_clean.shape)\n",
    "print(boundary_indices_evasion.shape)\n",
    "print(np.mean(percentiles))\n",
    "print(torch.mean(nodewise_nsa[boundary_indices_evasion]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d48b1a-cc47-417c-bbf9-a2d6a07ac8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_confidence=np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2]\n",
    "evasion_confidence=np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af04efa-eeeb-464e-a36c-f067a14975eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_correct_indices=np.argmax(probabilities_clean,axis=-1) == y.cpu().numpy()\n",
    "clean_correct_indices = np.where(clean_correct_indices==True)[0]\n",
    "evasion_correct_indices=np.argmax(probabilities_evasion,axis=-1) == y.cpu().numpy()\n",
    "evasion_correct_indices = np.where(evasion_correct_indices==True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af9cf2-7233-4208-a36d-ab21e1259a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_correct_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a65934-7d74-443b-b8c8-2a765266962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "guard_ec = evasion_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad0db0-6699-437e-af05-49a9e18acff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "print(np.count_nonzero((clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero((clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8b816-67f7-4a1e-99aa-bb6ae0b59c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_indices = np.argsort(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])[::-1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405e69f-8d54-4503-b375-b5bd28bcb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa.cpu().numpy()[worst_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1651a-4462-4d39-af39-0751a112faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "guard_nodewise_nsa = nodewise_nsa.cpu().numpy()[worst_indices]\n",
    "np.mean(guard_nodewise_nsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f6d49-36b6-42ac-b22a-21cc2c0582f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a75aa-3087-4d3d-aa15-e2b559167012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boundary_indices_clean.shape)\n",
    "print(boundary_indices_evasion.shape)\n",
    "print(np.mean(percentiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d55c5b",
   "metadata": {},
   "source": [
    "## ProGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb730a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_kwargs = dict(gnn_lr=0.01,gnn_weight_decay=0.0005,adj_lr=0.01,adj_momentum=0.9,reg_adj_deviate=1.0)\n",
    "\n",
    "def make_model(A):\n",
    "    return gb.model.ProGNN(A, GCN(n_feat=D, n_class=C, bias=True, activation=\"relu\", hidden_dims=[64],dropout=0.5)).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce222e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_model = make_model(A)\n",
    "model_args = filter_model_args(aux_model, A, X)\n",
    "aux_model.fit(model_args, y, train_nodes, val_nodes, progress=True, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb00025",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals = aux_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df2748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_accuracy = gb.metric.accuracy(aux_model(X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['ProGNN']['clean']=clean_accuracy\n",
    "\n",
    "print(\"Clean test acc:   \", clean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in clean_vals.items():\n",
    "    print(v.shape)\n",
    "    clean_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e633c-533e-4ab2-b9cc-098a4f483db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2 = {}\n",
    "for k,v in clean_vals.items():\n",
    "    clean_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24f457-09ff-4a39-9cab-089fdac71610",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102792f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez(f'feature_vals/prognn_clean_{ptb_value}.npz', **clean_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9fcb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Poisoning global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a9e2d-45be-484b-ad01-cb640b2de535",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65928a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_kwargs2 = dict(gnn_lr=0.01,gnn_weight_decay=0.0005,adj_lr=0.01,adj_momentum=0.9,reg_adj_deviate=1.0,\\\n",
    "                   adj_optim_interval = 2, reg_adj_l1 = 5e-4, reg_adj_nuclear = 0, reg_feat_smooth = 1e-3)\n",
    "\n",
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "    A_pert = A + A_diff\n",
    "\n",
    "    ############# Meta-Attack ############\n",
    "    model = make_model(A_pert)\n",
    "    model_args = filter_model_args(model, A_pert, X)\n",
    "    model.fit(model_args, y, train_nodes, val_nodes, progress=False, **fit_kwargs2, differentiable=A_pert.requires_grad)\n",
    "    #model.fit(X, y, train_nodes, val_nodes, progress=True, **fit_kwargs)\n",
    "    scores = model(X)\n",
    "    ######################################\n",
    "\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn,\\\n",
    "                                      base_lr=0.1, grad_clip=0.1)\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90019bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_model = make_model(A_pert)\n",
    "model_args = filter_model_args(pois_model, A_pert, X)\n",
    "pois_model.fit(model_args, y, train_nodes, val_nodes, progress=True, **fit_kwargs)\n",
    "pois_accuracy = gb.metric.accuracy(pois_model(X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['ProGNN']['pois']=pois_accuracy\n",
    "\n",
    "print(\"Poisoned test acc:\", pois_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_vals=pois_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0aa7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in pois_vals.items():\n",
    "    print(v.shape)\n",
    "    pois_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba961f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('feature_vals/prognn_gp_'+ptb_value+'.npz', **pois_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5824c3e",
   "metadata": {},
   "source": [
    "### Evasion global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "    A_pert = A + A_diff\n",
    "\n",
    "\n",
    "    ############# Aux-Attack #############\n",
    "    \n",
    "    model = aux_model\n",
    "    model.S = A_pert\n",
    "    scores = model(X)\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()\n",
    "\n",
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ed619",
   "metadata": {},
   "outputs": [],
   "source": [
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.1)\n",
    "\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)\n",
    "print(\"Adversarial edges:\", pert.shape[0])\n",
    "evas_accuracy = gb.metric.accuracy(aux_model(X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['ProGNN']['evas']=evas_accuracy\n",
    "\n",
    "print(\"Evasion test acc: \", evas_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2668690",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_model(X)\n",
    "evasion_vals=aux_model.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd919426",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in evasion_vals.items():\n",
    "    evasion_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d4bd1f-b836-46fd-98e7-9f248af3c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8d927-6dd9-48a3-a244-5ade29bc609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals2 = {}\n",
    "for k,v in evasion_vals.items():\n",
    "    evasion_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97efe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez('feature_vals/prognn_ge_'+ptb_value+'.npz', **evasion_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52007d65-84f9-4ee1-876f-13f717f4501c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Node Degree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb2d7f-f259-478c-8b14-0b2d2e1200f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(clean_vals2['conv1'],evasion_vals2['conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd55b5-9a57-45b7-9649-77894ea6dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43d783-b4f3-4e96-a1d2-aa8e4bc03f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how many edges were changed for each node\n",
    "edge_change = torch.abs(A - A_pert).sum(dim=1).cpu()\n",
    "print(sum(edge_change))\n",
    "print(len(torch.nonzero(edge_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e5d9c-f6a8-4d09-8bde-d397e0388580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how much the degree changed for each node\n",
    "degree_change = torch.abs(A.sum(dim=1) - A_pert.sum(dim=1)).cpu()\n",
    "print(sum(degree_change))\n",
    "print(len(torch.nonzero(degree_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8592d0-1f14-4a98-b4ba-f041b56307dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Ground truth scores\n",
    "\n",
    "# Pearson correlation for original embeddings\n",
    "pearson_corr_edge = pearsonr(nodewise_nsa, edge_change)\n",
    "print(f\"Pearson Correlation (edge): {pearson_corr_edge}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_degree = pearsonr(nodewise_nsa, degree_change)\n",
    "print(f\"Pearson Correlation (degree): {pearson_corr_degree}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_high = pearsonr(degree_change, edge_change)\n",
    "print(f\"Pearson Correlation (high): {pearson_corr_high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76138852-173a-4edd-8470-72f85397125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edge_changes = torch.sort(edge_change, descending=True)[1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19549ec0-812d-4a63-bcec-e97ee4c8ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_change[max_edge_changes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5902d8-7bed-4cd0-b00b-b8d9f1cfca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in max_edge_changes:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0]\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548a7ad-815b-4be1-bb10-596a73312416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "values = edge_change[max_edge_changes]\n",
    "percentiles = nodewise_nsa[max_edge_changes]\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "\n",
    "\n",
    "# Plotting the column chart\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Values', color=color)\n",
    "ax1.bar(range(len(values)), values, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Create a second y-axis for the percentiles\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Percentiles', color=color)\n",
    "ax2.plot(range(len(percentiles)), percentiles, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd86630-c44b-4fdb-ab4a-0d7c99530519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svd_percentile  = deepcopy(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d7c82-2036-4565-ae8d-603c8b239ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa_prognn = deepcopy(nodewise_nsa[max_edge_changes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63382fcd-ff91-4454-8749-31d597d4e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa_prognn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af364f-d4a8-4f57-ba42-5ce371c3dd8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e079a-f4aa-46de-9ee0-fd22582f16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_counts = []\n",
    "evasion_counts = []\n",
    "\n",
    "clean_misclassify = []\n",
    "evasion_misclassify = []\n",
    "for threshold in thresholds:\n",
    "    boundary_indices_clean = np.where(np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "    boundary_indices_evasion = np.where(np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]\n",
    "    clean_counts.append(boundary_indices_clean.shape[0])\n",
    "    evasion_counts.append(boundary_indices_evasion.shape[0])\n",
    "\n",
    "    if threshold==0:\n",
    "        clean_misclassify.append(0)\n",
    "        evasion_misclassify.append(0)\n",
    "        continue\n",
    "    #Calculate misclassified nodes at this threshold\n",
    "    misclassify_count_clean=np.count_nonzero(np.argmax(probabilities_clean[boundary_indices_clean],axis=-1) != y[boundary_indices_clean].cpu().numpy())\n",
    "    misclassify_count_evasion=np.count_nonzero(np.argmax(probabilities_evasion[boundary_indices_evasion],axis=-1) != y[boundary_indices_evasion].cpu().numpy())\n",
    "    #print(misclassify_count_clean)\n",
    "    clean_misclassify.append(misclassify_count_clean)\n",
    "    evasion_misclassify.append(misclassify_count_evasion)\n",
    "\n",
    "clean_counts=np.diff(clean_counts)\n",
    "evasion_counts=np.diff(evasion_counts)\n",
    "clean_misclassify = np.diff(clean_misclassify)\n",
    "evasion_misclassify = np.diff(clean_misclassify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7f3fb-220a-415f-8ad1-77be42ce0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "values1 = clean_counts[0:7]\n",
    "values2 = evasion_counts[0:7]\n",
    "plt.plot(values1)\n",
    "plt.plot(values2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c79be-f68c-477f-baa7-eeea322170ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "boundary_indices_clean = np.where(\\\n",
    "    np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "\n",
    "boundary_indices_evasion = np.where(\\\n",
    "    np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d1808-9d5a-4771-9e8a-025c042aaec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afc30e-406b-463d-ab1b-4179bec8edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodewise_nsa = nodewise_nsa[boundary_indices_evasion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e081f2-b557-4bc6-ad3c-90421ebed531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in boundary_indices_evasion:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0][0]\n",
    "    #print(position)\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed8660-cac7-43a9-ba48-f314b082db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa[boundary_indices_evasion].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a393f4-0dc7-42d0-97f2-0fb9a256fde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a5fe2-ef43-4bca-98c2-6d11ec5769d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boundary_indices_clean.shape)\n",
    "print(boundary_indices_evasion.shape)\n",
    "print(np.mean(percentiles))\n",
    "print(torch.mean(nodewise_nsa[boundary_indices_evasion]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306296f8-8d95-4524-a3db-a11bcc48f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_confidence=np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2]\n",
    "evasion_confidence=np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e71e57-ab4d-47a2-9b69-f51cdf6e739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prognn_ec = evasion_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ef4ec-4e4d-414c-bd04-e12d20d2522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_correct_indices=np.argmax(probabilities_clean,axis=-1) == y.cpu().numpy()\n",
    "clean_correct_indices = np.where(clean_correct_indices==True)[0]\n",
    "evasion_correct_indices=np.argmax(probabilities_evasion,axis=-1) == y.cpu().numpy()\n",
    "evasion_correct_indices = np.where(evasion_correct_indices==True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122e2b7-aed8-4fb9-b394-f1cd398cab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_correct_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc400508-3a44-4d3a-a88f-f9ca221007b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "print(np.count_nonzero((clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero((clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab545a5-af00-4f16-86a7-1f1cc0e929cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_indices = np.argsort(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])[::-1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f16a1-85aa-4f21-9037-be5f3cfdc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa.cpu().numpy()[worst_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac34c05-31af-46a7-b86f-505f148d7748",
   "metadata": {},
   "outputs": [],
   "source": [
    "prognn_nodewise_nsa = nodewise_nsa.cpu().numpy()[worst_indices]\n",
    "np.mean(prognn_nodewise_nsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e01c02-3d33-4869-be7a-933ed2f8b772",
   "metadata": {},
   "source": [
    "## GRAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs1 = dict(hidden_dims=[64],dropout=0.5)\n",
    "model_kwargs2 = dict(dropnode=0.5,mlp_input_dropout=0.5,order=2)\n",
    "\n",
    "def make_model():\n",
    "    return GRAND(MLP(n_feat=D, n_class=C, bias=True, **model_kwargs1),**model_kwargs2).cuda()\n",
    "\n",
    "#aux_model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_kwargs = dict(lr=0.1, weight_decay=1e-4)\n",
    "aux_model.fit((A,X), y, train_nodes, val_nodes, progress=True, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3fb17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_accuracy = gb.metric.accuracy(aux_model(A,X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GRAND']['clean']=clean_accuracy\n",
    "\n",
    "print(\"Clean test acc:   \", clean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e45d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals = aux_model.mlp.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acb518",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in clean_vals.items():\n",
    "    clean_vals[k] = v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f10f6-bc4c-4ebf-a90c-fe22254d711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2 = {}\n",
    "for k,v in clean_vals.items():\n",
    "    clean_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493fad1-6e4e-427d-8b6f-fb77315f7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez(f'feature_vals/grand_clean_{ptb_value}.npz', **clean_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7681edea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Poisoning global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8919174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "    A_pert = A + A_diff\n",
    "\n",
    "    ############# Meta-Attack ############\n",
    "    model = make_model()\n",
    "    model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs,max_epochs=100, differentiable=A_pert.requires_grad)\n",
    "    scores = model(A_pert, X)\n",
    "    ######################################\n",
    "\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ae992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn,\\\n",
    "                                      base_lr=0.1, grad_clip=0.1)\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_model = make_model()\n",
    "pois_model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "pois_accuracy = gb.metric.accuracy(pois_model(A_pert, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GRAND']['pois']=pois_accuracy\n",
    "\n",
    "print(\"Poisoned test acc:\", pois_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_vals = pois_model.mlp.feature_vals\n",
    "pois_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in pois_vals.items():\n",
    "    pois_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('feature_vals/grand_gp_'+ptb_value+'.npz', **pois_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7988d3f",
   "metadata": {},
   "source": [
    "### Evasion global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1767619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "    A_pert = A + A_diff\n",
    "\n",
    "\n",
    "    ############# Aux-Attack #############\n",
    "    model = aux_model\n",
    "    scores = model(A_pert, X)\n",
    "\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()\n",
    "\n",
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88173c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.1)\n",
    "\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)\n",
    "print(\"Adversarial edges:\", pert.shape[0])\n",
    "evas_accuracy = gb.metric.accuracy(aux_model(A_pert, X)[test_nodes], y[test_nodes]).item()\n",
    "accuracy_dict['GRAND']['evas']=evas_accuracy\n",
    "\n",
    "print(\"Evasion test acc: \", evas_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_model(A_pert,X)\n",
    "evasion_vals = aux_model.mlp.feature_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682deff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in evasion_vals.items():\n",
    "    evasion_vals[k]=v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.savez('feature_vals/grand_ge_'+ptb_value+'.npz', **evasion_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b94ac-9e22-4e39-956c-1743ac514671",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_vals2 = {}\n",
    "for k,v in evasion_vals.items():\n",
    "    evasion_vals2[k] = deepcopy(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefa78d-968d-4b34-8518-aa16161c53bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Node Degree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d95e44-fee9-4152-85a6-d0e145d4797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(clean_vals2['conv1'],evasion_vals2['conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86dd08-abb2-4b28-b537-83804dac0bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883e7fc-67a3-4194-a325-95473be07d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how many edges were changed for each node\n",
    "edge_change = torch.abs(A - A_pert).sum(dim=1).cpu()\n",
    "print(sum(edge_change))\n",
    "print(len(torch.nonzero(edge_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9ffe0-4f69-4358-8e7a-a114e9478d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This measures how much the degree changed for each node\n",
    "degree_change = torch.abs(A.sum(dim=1) - A_pert.sum(dim=1)).cpu()\n",
    "print(sum(degree_change))\n",
    "print(len(torch.nonzero(degree_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f615fd-e028-4647-81ff-2eb17577666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Ground truth scores\n",
    "\n",
    "# Pearson correlation for original embeddings\n",
    "pearson_corr_edge = pearsonr(nodewise_nsa, edge_change)\n",
    "print(f\"Pearson Correlation (edge): {pearson_corr_edge}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_degree = pearsonr(nodewise_nsa, degree_change)\n",
    "print(f\"Pearson Correlation (degree): {pearson_corr_degree}\")\n",
    "\n",
    "# Pearson correlation for reduced embeddings\n",
    "pearson_corr_high = pearsonr(degree_change, edge_change)\n",
    "print(f\"Pearson Correlation (high): {pearson_corr_high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93904d1e-1785-4115-8117-4ca5d00a80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edge_changes = torch.sort(edge_change, descending=True)[1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7b46f-5a37-495c-a842-49a641fd5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_change[max_edge_changes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cce30c-9fdb-455a-87a6-f3a6b7a43a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in max_edge_changes:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0]\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cc186-bb8c-4ab6-bd91-ee630391db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "values = edge_change[max_edge_changes]\n",
    "percentiles = nodewise_nsa[max_edge_changes]\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "\n",
    "\n",
    "# Plotting the column chart\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Values', color=color)\n",
    "ax1.bar(range(len(values)), values, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Create a second y-axis for the percentiles\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Percentiles', color=color)\n",
    "ax2.plot(range(len(percentiles)), percentiles, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b3a25-5307-4267-baa9-6ebf79e2af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svd_percentile  = deepcopy(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b61da9-3f91-46ee-a6a4-c0a8b3d6a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa_grand = deepcopy(nodewise_nsa[max_edge_changes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1009d-13db-4caf-a68a-bfc2210dcec1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d41d52-db95-496d-ac5a-896b6b7e6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_counts = []\n",
    "evasion_counts = []\n",
    "\n",
    "clean_misclassify = []\n",
    "evasion_misclassify = []\n",
    "for threshold in thresholds:\n",
    "    boundary_indices_clean = np.where(np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "    boundary_indices_evasion = np.where(np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]\n",
    "    clean_counts.append(boundary_indices_clean.shape[0])\n",
    "    evasion_counts.append(boundary_indices_evasion.shape[0])\n",
    "\n",
    "    if threshold==0:\n",
    "        clean_misclassify.append(0)\n",
    "        evasion_misclassify.append(0)\n",
    "        continue\n",
    "    #Calculate misclassified nodes at this threshold\n",
    "    misclassify_count_clean=np.count_nonzero(np.argmax(probabilities_clean[boundary_indices_clean],axis=-1) != y[boundary_indices_clean].cpu().numpy())\n",
    "    misclassify_count_evasion=np.count_nonzero(np.argmax(probabilities_evasion[boundary_indices_evasion],axis=-1) != y[boundary_indices_evasion].cpu().numpy())\n",
    "    #print(misclassify_count_clean)\n",
    "    clean_misclassify.append(misclassify_count_clean)\n",
    "    evasion_misclassify.append(misclassify_count_evasion)\n",
    "\n",
    "clean_counts=np.diff(clean_counts)\n",
    "evasion_counts=np.diff(evasion_counts)\n",
    "clean_misclassify = np.diff(clean_misclassify)\n",
    "evasion_misclassify = np.diff(clean_misclassify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27048457-197a-49a8-af26-3987fc0ca037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "values1 = clean_counts[0:7]\n",
    "values2 = evasion_counts[0:7]\n",
    "plt.plot(values1)\n",
    "plt.plot(values2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450aac3-85a0-4d81-813d-fdc8fa96939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "boundary_indices_clean = np.where(\\\n",
    "    np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2] < threshold)[0]\n",
    "\n",
    "boundary_indices_evasion = np.where(\\\n",
    "    np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2] < threshold)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3da99-613d-4b9c-b882-359dd3397580",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa = torch.mean(criterion_v2(clean_vals2['conv1'],evasion_vals2['conv1']),dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160ac0c-c632-496f-86f1-969346b9bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodewise_nsa = nodewise_nsa[boundary_indices_evasion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b040f6e-cb26-4477-bc3d-de95eaf290b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Sort the values\n",
    "sorted_values, sorted_indices = torch.sort(nodewise_nsa)\n",
    "\n",
    "# Calculate the percentiles/quantiles\n",
    "percentiles = []\n",
    "for index in boundary_indices_evasion:\n",
    "    position = (sorted_values == nodewise_nsa[index]).nonzero(as_tuple=True)[0][0]\n",
    "    #print(position)\n",
    "    percentile = (torch.true_divide(position, len(nodewise_nsa)) * 100).item()\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# Print the percentiles for the corresponding indices\n",
    "# for idx, percentile in zip(max_edge_changes, percentiles):\n",
    "#     print(f\"Node {idx} is in the {percentile} percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ba099-b6bd-4cba-a374-3a519ea65d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa[boundary_indices_evasion].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ac339-8e37-46c7-83e0-5c4c29bca098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a836fb7-a318-4289-bcda-c88e4c589593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boundary_indices_clean.shape)\n",
    "print(boundary_indices_evasion.shape)\n",
    "print(np.mean(percentiles))\n",
    "print(torch.mean(nodewise_nsa[boundary_indices_evasion]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d4dbc-2d4b-4e58-ac75-0f1cc4a0d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1]\n",
    "#thresholds = [0.2]\n",
    "probabilities_clean = F.softmax(clean_vals2['conv1'],dim=-1).numpy()\n",
    "probabilities_evasion = F.softmax(evasion_vals2['conv1'],dim=-1).numpy()\n",
    "clean_confidence=np.sort(probabilities_clean, axis=1)[:,-1] - np.sort(probabilities_clean, axis=1)[:,-2]\n",
    "evasion_confidence=np.sort(probabilities_evasion, axis=1)[:,-1] - np.sort(probabilities_evasion, axis=1)[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100efa42-0e0c-4838-8a81-cb7248138b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_ec = evasion_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70388f0f-db80-4ce6-b3aa-c9214274cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_correct_indices=np.argmax(probabilities_clean,axis=-1) == y.cpu().numpy()\n",
    "clean_correct_indices = np.where(clean_correct_indices==True)[0]\n",
    "evasion_correct_indices=np.argmax(probabilities_evasion,axis=-1) == y.cpu().numpy()\n",
    "evasion_correct_indices = np.where(evasion_correct_indices==True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58821bd0-abef-4f77-a775-8e427abea133",
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_correct_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740779dd-8044-4f91-a7de-35d10bc3aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "print(np.count_nonzero((clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence - evasion_confidence)>=threshold))\n",
    "print(np.count_nonzero((clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))\n",
    "print(np.count_nonzero(np.abs(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])>=threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d670556-fa20-4d45-a1ec-9f6330214d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_indices = np.argsort(clean_confidence[evasion_correct_indices] - evasion_confidence[evasion_correct_indices])[::-1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7988a7-2043-4109-9e22-d16cb473b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodewise_nsa.cpu().numpy()[worst_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4bbd42-9f13-44cd-bf04-c35832ce6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_nodewise_nsa = nodewise_nsa.cpu().numpy()[worst_indices]\n",
    "np.mean(grand_nodewise_nsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89e9e2-8000-46aa-91d7-16eebb51085b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0b861-072f-4dc3-a0bb-bc7488a6816d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boundary_indices_clean.shape)\n",
    "print(boundary_indices_evasion.shape)\n",
    "print(np.mean(percentiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745edf2e-ffc0-440e-bab6-d3adb2863b35",
   "metadata": {},
   "source": [
    "## Plot all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4d45e-559f-41c7-a555-b91b1689032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [gcn_ec, svd_ec, guard_ec, prognn_ec, grand_ec]\n",
    "outlier_counts = []\n",
    "for dataset in data:\n",
    "    Q1 = np.percentile(dataset, 25)\n",
    "    Q3 = np.percentile(dataset, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = np.sum((dataset < lower_bound) | (dataset > upper_bound))\n",
    "    outlier_counts.append(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18f6ea-ba32-420c-af5a-0cdfa48affdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d92e5-edeb-4221-910f-f8d32dd09a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,10))\n",
    "data = [gcn_ec, svd_ec, guard_ec, prognn_ec, grand_ec]\n",
    "labels = [\"GCN\",\"SVD-GCN\", \"GNNGuard\", \"ProGNN\", \"GRAND\"]\n",
    "sns.boxplot(data)\n",
    "plt.xticks(range(len(labels)),labels)\n",
    "for i in range(len(data)):\n",
    "    plt.text(i+0.4, 0.05, f'{outlier_counts[i]}', ha='center', va='bottom', fontsize=20)\n",
    "\n",
    "plt.ylabel('Classification Confidence', fontsize=20)\n",
    "#plt.xlabel('GNN Architecture', fontsize=24)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=25)\n",
    "#plt.title('Comparison of Confidence Levels Across Different Architectures')\n",
    "sns.set(style='whitegrid')\n",
    "plt.savefig(\"classification_confidence_evasion.png\", bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d667c-06ff-42f6-a589-2ae3ad63f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#321,354, 0.0383 | 670, 877, 0.0605 | 341, 343, 0.0169 | 464, 486, 0.0355 | 0.030\n",
    "differences = [354-321,877-670,343-341,486-464,0]\n",
    "nsa_values = [0.0383, 0.0605, 0.0169, 0.035, 0.030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe4f0a-d914-49b0-a3e6-66d5b5a14e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "values = differences\n",
    "percentiles = nsa_values\n",
    "labels = [\"GCN\",\"SVD-GCN\", \"GNNGuard\", \"ProGNN\", \"GRAND\"]\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# Plotting the column chart\n",
    "color = 'tab:blue'\n",
    "#ax1.set_xlabel('Architecture', fontsize=27)\n",
    "ax1.set_ylabel('Boundary Node Increase', color=color, fontsize=24)\n",
    "ax1.bar(labels, values, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "# Create a second y-axis for the percentiles\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('NSA of Boundary Nodes', color=color, fontsize=24)\n",
    "ax2.plot(range(len(percentiles)), percentiles, color=color)\n",
    "ax2.grid(False)\n",
    "#ax1.grid(False)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.yticks(fontsize=24)\n",
    "plt.savefig(\"boundary_node_increase.png\", bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88504afa-0ae6-4edd-86e1-9bd473f336aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "node_indices = range(len(grand_nodewise_nsa))\n",
    "\n",
    "# Create a line plot for each list\n",
    "plt.plot(node_indices, grand_nodewise_nsa, label='GRAND')\n",
    "plt.plot(node_indices, prognn_nodewise_nsa, label='ProGNN')\n",
    "plt.plot(node_indices, guard_nodewise_nsa, label='GNNGuard')\n",
    "plt.plot(node_indices, svd_nodewise_nsa, label='SVD-GCN')\n",
    "plt.plot(node_indices, gcn_nodewise_nsa, label='GCN')\n",
    "\n",
    "# Adding labels and title\n",
    "#plt.xlabel('Node Index',fontsize=17)\n",
    "plt.ylabel('Nodewise NSA Value',fontsize=27)\n",
    "#plt.title('Nodewise NSA values for the top 50 nodes with the greatest decline in Classification Confidence')\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=27)\n",
    "# Add a legend\n",
    "plt.legend(fontsize=20)\n",
    "plt.savefig(\"nodewise_confidence.png\", bbox_inches='tight')\n",
    "# Show the plot\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9caa39b-1433-408e-b61f-754d3d9f71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "node_indices = range(len(nodewise_nsa_grand))\n",
    "\n",
    "# Create a line plot for each list\n",
    "plt.plot(node_indices, nodewise_nsa_grand, label='GRAND')\n",
    "plt.plot(node_indices, nodewise_nsa_prognn, label='ProGNN')\n",
    "plt.plot(node_indices, nodewise_nsa_guard, label='GNNGuard')\n",
    "plt.plot(node_indices, nodewise_nsa_svd, label='SVD-GCN')\n",
    "plt.plot(node_indices, nodewise_nsa_gcn, label='GCN')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Node Index')\n",
    "plt.ylabel('Nodewise NSA Value')\n",
    "plt.title('Nodewise NSA values for the top 50 nodes with the highest degree variance')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fdb86-3a8a-45a2-a9f0-ff52b5021bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53086bad-e1e5-45e5-b791-adab9af2713b",
   "metadata": {},
   "source": [
    "## Save the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0794a-7912-44ae-afd1-fb340713a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf793b9-8e91-40b9-959f-00d701b4abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "!mkdir accuracy_vals\n",
    "import pickle\n",
    "save_path = 'accuracy_vals/'+ptb_value+'.pkl'\n",
    "with open(save_path, 'wb') as file:\n",
    "    pickle.dump(accuracy_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
